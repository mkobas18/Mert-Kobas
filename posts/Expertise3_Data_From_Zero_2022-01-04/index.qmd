---
title: "Expertise3 Data Analysis from the very beginning"
author: "MK"
date: "2023-01-16"
categories: [example data, code, analysis]
image: "newdata.png"
---

This post includes the trial analyses of an example data related to expertise.

### Import necessary packages and expertise data

```{r warning = FALSE, message = FALSE}
#Import library ----
library(tidyverse)
library(readr)
library(purrr)
library(jmv)
library(psych)
library(DescTools)
library(stats)
library(factoextra)

#Read the csv file ----
Expertise3 <- read_csv("~/Desktop/Expertise3_December 23, 2022_10.53.csv")

```

Creates a new dataframe called expertise3_clean, which is a copy of the original dataframe called Expertise3 and removes the second row of the dataframe and create a variable called column_names and assign it the names of the columns in the dataframe and change the column names

```{r warning = FALSE, message = FALSE}


#removes the second row of the dataframe
expertise3_clean<-Expertise3%>% 
  slice(-2) 


#selects all columns except the ones listed 
expertise3_clean <- expertise3_clean %>%
  select(-StartDate, -EndDate, -Status, -Progress,-ResponseId,-RecordedDate,-RecipientLastName, -RecipientFirstName,-RecipientEmail, -ExternalReference, -LocationLatitude,-LocationLongitude, -DistributionChannel, -UserLanguage)

#create a variable called column_names and assign it the names of the columns in the dataframe
column_names <- names(expertise3_clean)

##Change the column names ----
colnames(expertise3_clean) <- c('ip','duration', 'finished', 'stih_lang','r_ih_lang','stih_school','r_ih_school',
                                'stih_cards','r_ih_cards','stih_breakfast','r_ih_breakfast','stih_weddings','r_ih_weddings',
                                'stih_teeth','r_ih_teeth','stih_traffic','r_ih_traffic','stih_tv','r_ih_tv',
                                'know_lang','know_school','know_cards','know_breakfast','know_weddings','know_teeth',
                                'know_traffic','know_tv',
                                'course_lang','high_lang', 'colle_lang', 'grad_lang',
                                'book_lang','numbook_lang','article_lang','numarticle_lang',
                                'course_school','high_school', 'colle_school', 'grad_school',
                                'book_school','numbook_school','article_school','numarticle_school',
                                'course_cards','high_cards', 'colle_cards', 'grad_cards',
                                'book_cards','numbook_cards','article_cards','numarticle_cards',
                                'course_breakfast','high_breakfast', 'colle_breakfast', 'grad_breakfast',
                                'book_breakfast','numbook_breakfast','article_breakfast','numarticle_breakfast',
                                'course_weddings','high_weddings', 'colle_weddings', 'grad_weddings',
                                'book_weddings','numbook_weddings','article_weddings','numarticle_weddings',
                                'course_teeth','high_teeth', 'colle_teeth', 'grad_teeth',
                                'book_teeth','numbook_teeth','article_teeth','numarticle_teeth',
                                'course_traffic','high_traffic', 'colle_traffic', 'grad_traffic',
                                'book_traffic','numbook_traffic','article_traffic','numarticle_traffic',
                                'course_tv','high_tv', 'colle_tv', 'grad_tv',
                                'book_tv','numbook_tv','article_tv','numarticle_tv',
                                'needforcog1','needforcog2','needforcog3','needforcog4','needforcog5','needforcog6',
                                'needforcog7','needforcog8','needforcog9','needforcog10','needforcog11','needforcog12',
                                'needforcog13','needforcog14','needforcog15','needforcog16','needforcog17','needforcog18',
                                'otherways','sex','birthdate','education','income','religion','identity','age','political_atti',
                                'english_level','proceure_confu','whatwestudied','moretothisstudy','additional_thoughts','attention')


```

### Questionnaire Items

The code below shows the survey items:

```{r warning = FALSE, message = FALSE}

#selects all columns except the ones specified
row_values <- expertise3_clean %>%
  select(-duration,-finished, -ip)%>%
  #selects only the first row
  filter(row_number() == 1)

#Items in the questionnaire ----

#unlist the row_values
row_values <- unlist(row_values)

my_list <- map(row_values, ~paste0(.))

library(stringr)
my_list <- str_replace(my_list, "(?<! )\\n(?! )", "")
my_list <- str_replace(my_list, "[^\\s]*\\\\n[^\\s]*", "")
list_string <- paste0("* ", paste(my_list, collapse = "\n* "))

##Show the survey items ----
cat(list_string)
```

### Exclusion Criterias

Data preparation for further analyses

```{r warning = FALSE, message = FALSE}

#Attention check and deletion of cases that didn't attend or finish the study ----
expertise3_new<-expertise3_clean%>%
  filter(attention==1&finished==1)


##Exclude the participants that joined outside of US ----

#view(expertise3_new)
expertise3_new<-expertise3_new%>%
  filter(ip!="37.221.172.194")

expertise3_new <- expertise3_new %>%
  filter(!(ip %in% c("77.198.10.26", "83.233.218.246", "189.172.66.106", "190.167.6.137")))

##selecting the columns that we want to keep ----
expertise3_new<-expertise3_new%>%
  select(-finished,-otherways,-birthdate,-proceure_confu,-whatwestudied,-moretothisstudy,-additional_thoughts,-attention)

#adds a column to the dataframe, with the name "id"
expertise3_new<-cbind(ID = 1:nrow(expertise3_new), expertise3_new)

# Numeric variables ----
# Change the data type of the variables to numeric 
expertise3_new <- expertise3_new %>%
  mutate_at(vars(stih_lang, r_ih_lang, stih_school, r_ih_school, stih_cards, r_ih_cards, stih_breakfast, r_ih_breakfast, 
                 stih_weddings, r_ih_weddings, stih_teeth, r_ih_teeth, stih_traffic, r_ih_traffic, stih_tv, r_ih_tv), as.numeric)


```

## Correlation for ih scores

Check the correlations between inherence (the variables starting with st) and reverse inherence (the variables starting with r) scores to check whether it's appropriate for averaging

```{r warning = FALSE, message = FALSE}

# Correlations between ih scores ----

# Create a list of variable names
variables <- c("stih_lang", "r_ih_lang", "stih_school", "r_ih_school", "stih_cards", "r_ih_cards", "stih_breakfast", "r_ih_breakfast", "stih_weddings", "r_ih_weddings", "stih_teeth", "r_ih_teeth", "stih_traffic", "r_ih_traffic", "stih_tv", "r_ih_tv")

# Initialize an empty data frame to store the correlation coefficients
correlations <- data.frame(variable1 = character(), variable2 = character(), correlation = numeric(), p.value = numeric(), conf.int = character())

# Iterate over the pairs of variables
for (i in seq(1, length(variables), 2)) {
  j <- i + 1
  
  # Calculate the Pearson correlation coefficient and test the statistical significance
  correlation_test <- cor.test(expertise3_new[, variables[i]], expertise3_new[, variables[j]], method = "pearson")
  
  # Add the correlation coefficient, p-value, and confidence interval to the data frame
  correlations <- rbind(correlations, data.frame(variable1 = variables[i], variable2 = variables[j], correlation = correlation_test$estimate, p.value = correlation_test$p.value, conf.int = paste(correlation_test$conf.int[1], correlation_test$conf.int[2], sep = " - ")))}

## View the correlation coefficients and statistical measures ----
correlations
```

## IH scores calculation

It seems that each pairs have negative significant correlation, so we can take the average scores to calculate inherence scores

```{r warning = FALSE, message = FALSE}

## Average of ih scores  ----
#It seems that each pairs have negative significant correlation, so we can take the average scores to measure inherence scores
expertise3_new <- expertise3_new %>%
  mutate(ih_lang = (stih_lang + (10 - r_ih_lang))/2,
         ih_school = (stih_school + (10 - r_ih_school)) / 2,
         ih_cards = (stih_cards + (10 - r_ih_cards)) / 2,
         ih_breakfast = (stih_breakfast + (10 - r_ih_breakfast)) / 2,
         ih_weddings = (stih_weddings + (10 - r_ih_weddings)) / 2,
         ih_teeth = (stih_teeth + (10 - r_ih_teeth)) / 2,
         ih_traffic = (stih_traffic + (10-r_ih_traffic)) / 2,
         ih_tv = (stih_tv + (10-r_ih_tv)) / 2 )

```

## Need for Cognition scores calculation

Calculate "Need for cognition" scale scores

```{r warning = FALSE, message = FALSE}
# Need for cognition scale scores  ----

# change the data type of the variables to numeric
expertise3_new <- expertise3_new %>%
  mutate_at(vars(needforcog1,needforcog2,needforcog3,needforcog4,needforcog5,needforcog6
                 ,needforcog7,needforcog8,needforcog9,needforcog10,needforcog11,needforcog12,
                 needforcog13,needforcog14,needforcog15,needforcog16,needforcog17,needforcog18), as.numeric)

## Calculate needforcog scores  ----
#add a new variable called needforcog, which is the sum of all the need for cognition items, the items are weighted according to the scoring key
expertise3_new <- expertise3_new %>%
  group_by(ID)%>%
  mutate(needforcog=(needforcog1+needforcog2+
                       (10-needforcog3)+(10-needforcog4)+(10-needforcog5)+needforcog6+
                       (10-needforcog7)+(10-needforcog8)+(10-needforcog9)+
                       needforcog10+needforcog11+(10-needforcog12)+
                       needforcog13+needforcog14+needforcog15+
                       (10-needforcog16)+(10-needforcog17)+needforcog18)/18)
```

## Data preparation

Prepare the expertise scores and other scores ready for analyses

```{r warning = FALSE, message = FALSE}

# Replace expertise variables' NA values in the expertise columns with 0  ----
variables <- c('high_lang', 'colle_lang', 'grad_lang',
               'numbook_lang','numarticle_lang',
               'high_school', 'colle_school', 'grad_school',
               'numbook_school','numarticle_school',
               'high_cards', 'colle_cards', 'grad_cards',
               'numbook_cards','numarticle_cards',
               'high_breakfast', 'colle_breakfast', 'grad_breakfast',
               'numbook_breakfast','numarticle_breakfast',
               'high_weddings', 'colle_weddings', 'grad_weddings',
               'numbook_weddings','numarticle_weddings',
               'high_teeth', 'colle_teeth', 'grad_teeth',
               'numbook_teeth','numarticle_teeth',
               'high_traffic', 'colle_traffic', 'grad_traffic',
               'numbook_traffic','numarticle_traffic',
               'high_tv', 'colle_tv', 'grad_tv',
               'numbook_tv','numarticle_tv')

expertise3_new[variables] <- lapply(expertise3_new[variables], 
                                    function(x) ifelse(is.na(x), 0, ifelse(x=='no',0,x)))

# Missing values in the dataframe  ----
apply(is.na(expertise3_new), 2, sum)


# Expertise Ready Df ----

# Create new data frame as analyzable 
expertise3_new<-expertise3_new%>%
  select(-stih_lang,-r_ih_lang,-stih_school,-r_ih_school,
         -stih_cards,-r_ih_cards,-stih_breakfast,-r_ih_breakfast,
         -stih_weddings,-r_ih_weddings,
         -stih_teeth,-r_ih_teeth,-stih_traffic,-r_ih_traffic,
         -stih_tv,-r_ih_tv,
         -course_lang,
         -book_lang,-article_lang,
         -course_school,
         -book_school,-article_school,
         -course_cards,
         -book_cards,-article_cards,
         -course_breakfast,
         -book_breakfast,-article_breakfast,
         -course_weddings,
         -book_weddings,-article_weddings,
         -course_teeth,
         -book_teeth,-article_teeth,
         -course_traffic,
         -book_traffic,-article_traffic,
         -course_tv,
         -book_tv,-article_tv,
         -needforcog1,-needforcog2,-needforcog3,-needforcog4,-needforcog5,-needforcog6,
         -needforcog7,-needforcog8,-needforcog9,-needforcog10,-needforcog11,-needforcog12,
         -needforcog13,-needforcog14,-needforcog15,-needforcog16,-needforcog17,-needforcog18)


# change the data type of the variables to numeric
expertise3_new <- expertise3_new %>%
  mutate_at(vars('know_lang','know_school','know_cards','know_breakfast',
                 'know_weddings','know_teeth','know_traffic','know_tv',
                 'high_lang', 'colle_lang', 'grad_lang',
                 'numbook_lang','numarticle_lang',
                 'high_school', 'colle_school', 'grad_school',
                 'numbook_school','numarticle_school',
                 'high_cards', 'colle_cards', 'grad_cards',
                 'numbook_cards','numarticle_cards',
                 'high_breakfast', 'colle_breakfast', 'grad_breakfast',
                 'numbook_breakfast','numarticle_breakfast',
                 'high_weddings', 'colle_weddings', 'grad_weddings',
                 'numbook_weddings','numarticle_weddings',
                 'high_teeth', 'colle_teeth', 'grad_teeth',
                 'numbook_teeth','numarticle_teeth',
                 'high_traffic', 'colle_traffic', 'grad_traffic',
                 'numbook_traffic','numarticle_traffic',
                 'high_tv', 'colle_tv', 'grad_tv',
                 'numbook_tv','numarticle_tv'), as.numeric)

```

## Long format

Long format of expertise dataset for factor analysis

```{r warning = FALSE, message = FALSE}
library('reshape2')

expertise3_factor <- melt(expertise3_new, id.vars = c("ID",'duration',"sex" ,"education" ,"income","religion",'identity','age','political_atti','english_level','needforcog'), 
                        measure.vars = c("ih_lang", "ih_school","ih_cards", "ih_breakfast", "ih_weddings", 
                                         "ih_teeth", "ih_traffic", "ih_tv",'know_lang','know_school','know_cards','know_breakfast',
                                         'know_weddings','know_teeth','know_traffic','know_tv',
                                         'high_lang', 'colle_lang', 'grad_lang',
                                         'numbook_lang','numarticle_lang',
                                         'high_school', 'colle_school', 'grad_school',
                                         'numbook_school','numarticle_school',
                                         'high_cards', 'colle_cards', 'grad_cards',
                                         'numbook_cards','numarticle_cards',
                                         'high_breakfast', 'colle_breakfast', 'grad_breakfast',
                                         'numbook_breakfast','numarticle_breakfast',
                                         'high_weddings', 'colle_weddings', 'grad_weddings',
                                         'numbook_weddings','numarticle_weddings',
                                         'high_teeth', 'colle_teeth', 'grad_teeth',
                                         'numbook_teeth','numarticle_teeth',
                                         'high_traffic', 'colle_traffic', 'grad_traffic',
                                         'numbook_traffic','numarticle_traffic',
                                         'high_tv', 'colle_tv', 'grad_tv',
                                         'numbook_tv','numarticle_tv'),
                        sep = "_", variable.name = "Category", value.name = "Score")

# Split the Category column into two columns based on the underscore separator
expertise3_factor <- expertise3_factor %>% separate(Category, into = c("Category", "Score_Type"), sep = "_")

## spread the data from long to wide format  ----
expertise3_fact <- expertise3_factor %>% spread(Category, Score)

# change the score type to a factor
expertise3_fact$Score_Type<-as.factor(expertise3_fact$Score_Type)

# convert the column ih to numeric
expertise3_fact$ih<-as.numeric(expertise3_fact$ih)
```

###Create another data frame to winsorize expertise variables before factor analysis
```{r}
expertise3_wins_fact<-expertise3_fact
```


## Factor analysis

Factor analysis for expertise variables with raw scores

```{r warning = FALSE, message = FALSE}
# Factor analysis for expertise variables with raw scores ----

# Import packages 

library(psych) #PCA/EFA analysis
library(REdaS) #Produces KMO and Bartletts test
library(GPArotation)


# Create a new dataframe that include only related variables
factor_exp<-expertise3_fact%>%
  select(colle, grad, high, numarticle, numbook)

# Check missing values
apply(is.na(factor_exp), 2, sum)

# Since grad classes for TV category is missing (nobody takes any class in the sample), listwise deletion is applied here.
bart_spher(factor_exp, use = "complete.obs") ###### produces Bartletts test of spherecity 

KMO(factor_exp)       ###### Kaiser-Meyer-Olkin measure, which is above .5.

# Let's check all the variables
fa(factor_exp, nfactors = 5, rotate =  "oblimin" )  

# So we can reduce it to 2 factors
fa(factor_exp, nfactors = 2, rotate =  "oblimin" )  

# Figure for the analysis

M1<-fa(factor_exp, nfactors = 2, rotate =  "oblimin" ) ##save the analysis as the object m1
fa.diagram(M1,main="Expertise Variables")  

```

### Eigenvalues

```{r}
#Check eigenvalues

fa.parallel(factor_exp)
```

### Extracting factor values

```{r warning = FALSE, message = FALSE}
factor_exp_score <- factanal(factor_exp, factors=2, scores="regression", rotation = "oblimin")

head(factor_exp_score$scores)

factor_exp_comb <- bind_cols(factor_exp, data.frame(factor_exp_score$scores))

factor_exp_comb$class<-factor_exp_comb$Factor1

factor_exp_comb$media_grad<-factor_exp_comb$Factor2

```

### Histogram and descriptives for factor scores

```{r warning = FALSE, message = FALSE}
descriptives(dat=factor_exp_comb, vars(Factor1, Factor2),
             sd=T)

```

```{r warning = FALSE, message = FALSE}
hist(factor_exp_comb$Factor1)

```

```{r warning = FALSE, message = FALSE}
hist(factor_exp_comb$Factor2)
```

```{r}

# Standardize the Selected variables  ----
vars_to_standardize <- c('know_lang','know_school','know_cards','know_breakfast',
                         'know_weddings','know_teeth','know_traffic','know_tv',
                         'high_lang', 'colle_lang', 'grad_lang',
                         'numbook_lang','numarticle_lang',
                         'high_school', 'colle_school', 'grad_school',
                         'numbook_school','numarticle_school',
                         'high_cards', 'colle_cards', 'grad_cards',
                         'numbook_cards','numarticle_cards',
                         'high_breakfast', 'colle_breakfast', 'grad_breakfast',
                         'numbook_breakfast','numarticle_breakfast',
                         'high_weddings', 'colle_weddings', 'grad_weddings',
                         'numbook_weddings','numarticle_weddings',
                         'high_teeth', 'colle_teeth', 'grad_teeth',
                         'numbook_teeth','numarticle_teeth',
                         'high_traffic', 'colle_traffic', 'grad_traffic',
                         'numbook_traffic','numarticle_traffic',
                         'high_tv', 'colle_tv', 'grad_tv',
                         'numbook_tv','numarticle_tv')

expertise3_new[, vars_to_standardize] <- scale(expertise3_new[, vars_to_standardize])

```

## Long format (with factor scores)

Long format of expertise dataset

```{r}

library('reshape2')

expertise3_long <- melt(expertise3_new, id.vars = c("ID",'duration',"sex" ,"education" ,"income","religion",'identity','age','political_atti','english_level','needforcog'), 
                        measure.vars = c("ih_lang", "ih_school","ih_cards", "ih_breakfast", "ih_weddings", 
                                         "ih_teeth", "ih_traffic", "ih_tv",'know_lang','know_school','know_cards','know_breakfast',
                                         'know_weddings','know_teeth','know_traffic','know_tv',
                                         'high_lang', 'colle_lang', 'grad_lang',
                                         'numbook_lang','numarticle_lang',
                                         'high_school', 'colle_school', 'grad_school',
                                         'numbook_school','numarticle_school',
                                         'high_cards', 'colle_cards', 'grad_cards',
                                         'numbook_cards','numarticle_cards',
                                         'high_breakfast', 'colle_breakfast', 'grad_breakfast',
                                         'numbook_breakfast','numarticle_breakfast',
                                         'high_weddings', 'colle_weddings', 'grad_weddings',
                                         'numbook_weddings','numarticle_weddings',
                                         'high_teeth', 'colle_teeth', 'grad_teeth',
                                         'numbook_teeth','numarticle_teeth',
                                         'high_traffic', 'colle_traffic', 'grad_traffic',
                                         'numbook_traffic','numarticle_traffic',
                                         'high_tv', 'colle_tv', 'grad_tv',
                                         'numbook_tv','numarticle_tv'),
                        sep = "_", variable.name = "Category", value.name = "Score")

# Split the Category column into two columns based on the underscore separator
expertise3_long <- expertise3_long %>% separate(Category, into = c("Category", "Score_Type"), sep = "_")

## spread the data from long to wide format  ----
expertise3_ready <- expertise3_long %>% spread(Category, Score)

# change the score type to a factor
expertise3_ready$Score_Type<-as.factor(expertise3_ready$Score_Type)

# convert the column ih to numeric
expertise3_ready$ih<-as.numeric(expertise3_ready$ih)

# Combine factor scores with the final data ----
expertise3_ready<-bind_cols(expertise3_ready,factor_exp_comb$Factor1,factor_exp_comb$Factor2)

#Rename the combined factor variables
expertise3_ready<-rename(expertise3_ready, classroom=...20)
expertise3_ready<-rename(expertise3_ready, media_grad=...21)


```

## Models

We can start to analyze our models with using hlm:

```{r warning = FALSE, message = FALSE}

## Import packages ----
library(lme4) 

library(lmerTest)

# Center variables: need for cognition and know 

expertise3_ready$know_cent <- scale(expertise3_ready$know, center = TRUE, scale = FALSE)

expertise3_ready$needforcog_cent <- scale(expertise3_ready$needforcog, center = TRUE, scale = FALSE)

expertise3_ready$class_cent <- scale(expertise3_ready$classroom, center = TRUE, scale = FALSE)

expertise3_ready$media_cent <- scale(expertise3_ready$media_grad, center = TRUE, scale = FALSE)

# Check descriptives

describe(expertise3_ready)
```

### Model of objective expertise, perceived expertise and need for cognition without interaction

```{r warning = FALSE, message = FALSE}

## Model 1 ----

# Need for cognition and perceived expertise as fixed effects
Model.1<-lmer(ih ~class_cent + media_cent + know_cent + needforcog_cent +(1|Score_Type)+(1|ID),   
              data=expertise3_ready)
summary(Model.1)
confint(Model.1)

```

So it seems that perceived knowledge and need for cognition are related to inherence significantly. Interestingly, need for cognition interaction is negatively related to inherence scores.People seek out tasks that challenge their abilities may show less inherent bias contained explanations and if they think they know that area, they agree with inherence bias included sentences more. IPeople may overestimate their abilities and they produce/comprehend the explanations with inherence bias more likely. Not suprisingly, people who are seeking for cognitive activities (need for cognition) may also show more effort for the explanations.

### Model of objective expertise, perceived expertise and need for cognition with interaction

```{r warning = FALSE, message = FALSE}

## Model 2 ----

Model.2<-lmer(ih ~class_cent + media_cent + know_cent + needforcog_cent + 
                needforcog*class_cent + needforcog*media_cent + needforcog*know +
                (1|Score_Type)+(1|ID), data=expertise3_ready)
summary(Model.2)
confint(Model.2)

```

## Histograms for Factors

```{r warning = FALSE, message = FALSE}
##Histogram, descriptives and correlation matrix for new factors ----
descriptives(dat=factor_exp_comb, vars(Factor1, Factor2),
             sd=T, skew =T)

```

```{r}

hist(factor_exp_comb$Factor1)

```

```{r}
hist(factor_exp_comb$Factor2)
```

So our descriptive stats and graphs showed there is an extreme skewness due to extreme values in our factors.


## Winsorize the variables at 1%

```{r warning = FALSE, message = FALSE}
# winsorize the variables (at 1%)
expertise3_ready <- expertise3_ready%>%
  mutate(numarticle_wins_1=Winsorize(numarticle, probs = c(0,0.99)), 
         numbook_wins_1=Winsorize(numbook, probs = c(0,0.99)),
         high_wins_1=Winsorize(high, probs = c(0,0.99)),
         colle_wins_1=Winsorize(colle, probs = c(0,0.99)),
         grad_wins_1=Winsorize(grad,na.rm=TRUE, probs = c(0,0.99)),
         classroom_wins_1=Winsorize(classroom,na.rm=TRUE, probs = c(0,0.99)),
         media_wins_1=Winsorize(media_grad,na.rm=TRUE, probs = c(0,0.99)))

#check descriptives
descriptives(dat=expertise3_ready, vars(classroom_wins_1,media_wins_1), median=F, n=F, missing=F, sd=T, skew =T)

descriptives(dat=expertise3_ready, vars(high_wins_1, colle_wins_1), median=F, n=F, missing=F, sd=T)

descriptives(dat=expertise3_ready, vars(numarticle_wins_1, numbook_wins_1, grad_wins_1), median=F, n=F, missing=F, sd=T)

```

```{r warning = FALSE, message = FALSE}
hist(expertise3_ready$classroom_wins_1)

```

Our first factor is negatively skewed

```{r warning = FALSE, message = FALSE}
hist(expertise3_ready$media_wins_1)

```

```{r}
# Center variables: 

expertise3_ready$classroom_wins_1_cent <- scale(expertise3_ready$classroom_wins_1, center = TRUE, scale = FALSE)

expertise3_ready$media_wins_1_cent <- scale(expertise3_ready$media_wins_1, center = TRUE, scale = FALSE)

```

## HLM Models

Since expertise can be objective (based on the experience like problem solving in that area or productions, year of education or spending more time about that topic) and subjective (how much people perceived themselves as knowledgeable about that topic), objective expertise or real expertise will be negatively related to inherence scores, which means that real experts, which spend more time to learn that subject through courses or pressed materials -books, magazines, articles-, will not satisfy with heuristic explanations. Experts produced more features in diagnostic categories like to describe depression, they listed more attributes for this category (Murphy & Wright, 1984). Therefore, it can be argued that they will evaluate the cases with both intrinsic and extrinsic factors, so they have less scores for inherency.

Besides this, our expertise variables and engaging in cognitive activities may be interact because expertise sources such as books or magazines also contain products of heuristic thinking. People who have low scores in need for cognition trusted these kind of external sources besides cognitive heuristics:

"Research relating need for cognition to other individual-differences variables provides evidence that individuals high in need for cognition naturally tend to seek, acquire, think about, and reflect back on information to make sense of stimuli, relationships, and events in their world; individuals low in need for cognition, in contrast, are more likely to rely on others (e.g., experts), cognitive heuristics, or social comparison processes to provide this structure." (Cacioppo et al., 1996, p.243)

As a result of this, even if people who read more books, magazines or take more grad courses, they would probably satisfy with sentences that include inherence bias more or less depend on their need for cognition score, so the assumption is the interaction between need for cognition and this expertise factor will be significantly related to inherence scores.

### Model objective expertise with grad courses, books and magazines

```{r warning = FALSE, message = FALSE}
## Model objective expertise ----

Model_obj<-lmer(ih ~media_wins_1_cent*needforcog_cent+media_wins_1_cent+needforcog_cent+
                (1|Score_Type)+(1|ID), data=expertise3_ready)
summary(Model_obj)


```

The results showed that not the interaction but main effects significantly related to inherence scores. It's maybe because of low power to detect interaction or because people with high need for cognition scores also take these courses and read these books due to their tendencies, so there is not an interaction. Media and grad courses expertise is related to inherence scores negatively, adjusting for need for cognition scores. I think these results may tap to the role of memory limitations in heuristic thinking. If experts can produce more hypotheses with using their long term memory, the recent memory traces would be remembered probably better. Especially grad courses and also books and magazines seem to related this. Furthermore, especially grad courses again, can be more challenging for the related area. For example, a course related to language may be challenging or understanding books required more attention to details and different backgrounds about these topics so these people already have an expanded mental shotgun area/stage. Inherence bias occurs as a result of memory limitations, so having active memory traces (and broad mental shotgun representations) may provide these people to think beyond heuristic thinking with inherence bias.

I would expect the same result with high school and college courses, the relation may be more weak because these courses may not be recent, so let's check the model:

### Model objective expertise with high school and college courses
```{r}
Model_obj2<-lmer(ih ~classroom_wins_1_cent * needforcog_cent +classroom_wins_1_cent + needforcog_cent+(1|Score_Type)+(1|ID), data=expertise3_ready)
summary(Model_obj2)

```
These results showed that the interaction is significant, so the relation between class and inherence scores is depend on need for cognition scores. However, since the trend of the relation between class and inherence scores is positive, this interaction seems negative, so need for cognition mitigated this relation. Commenting this counter intuitive result may be a better way to understand this interaction:

Main effect of class is not significant (the relation between high school and undergraduate courses and inherence scores). This may be as a result of not challenging nature of these courses or they may not be remembered very well, if these people didn't interest in them later. The positive trend may be a product of perceived expertise, so people who take these courses think themselves as experts but they are not. However if they have tendency to engage in cognitive activities, they still trust cognitive heuristics less, so need for cognition interact with this relation.

What about perceived expertise? I think perceived expertise may be misleading for people because especially for daily topics like breakfast, they may think that they know enough but their knowledge is limited (and they produce less diverse facts during mental shotgun stage). However, the need for cognition also moderates this relation. Let's check:

### Model of perceived expertise and need for cognition
```{r}
Model_perc<-lmer(ih ~know_cent*needforcog_cent+ know_cent + needforcog_cent +
                (1|Score_Type)+(1|ID), data=expertise3_ready)
summary(Model_perc)
```

These results are similar to previous one and the relation between perceived knowledge and inherence scores moderated by need for cognition, which means people may overinterpret their knowledge and tend to think heuristically more due to this, but their tendency to engage in cognitive activities change this relation, if they like to engage in cognitive activities more, they satisfy with inherent explanations less even if they overestimate their knowledge about that area. This result partially support and partially conflict with Pennycook et al. (2017). Partially supported because just like that research, we found that people are unaware of their own inherence bias and this may be one of the reason behind inherence bias. However, they also found that Dunning-Kruger effects influence their need for cognition scores, so they also overestimate their need for cognition scores. Unlike my assumption here (the mitigating factor in engaging cognitive activities), their finding taps that perceived knowledge should be positively related to need for cognition:


```{r}
corrMatrix(expertise3_ready,
           vars = vars(know_cent,needforcog_cent), flag = TRUE)
```

However our scores showed that they are not related significantly.
After all of these let's check our first model 1 and model 2 to adjust other variables:

### Model of objective expertise, perceived expertise and need for cognition without interaction

```{r}
Model.1.1<-lmer(ih ~classroom_wins_1_cent + media_wins_1_cent + know_cent +needforcog_cent +(1|Score_Type)+(1|ID),   
              data=expertise3_ready)
summary(Model.1.1)
```

The same comments can be done also here, our results are not different than single models. This model may be better because it also adjusts perceived expertise and need for cognition, when the objective expertise variables are explained and vice versa. Therefore, our media and grad class related factor is still negatively related to inherence score when it was adjusted for perceived knowledge, class and need for cognition. Let's check the model with interaction:

### Model of objective expertise, perceived expertise and need for cognition with interaction

```{r}
Model.2.1<-lmer(ih ~classroom_wins_1_cent + media_wins_1_cent + know_cent+needforcog_cent + classroom_wins_1_cent*needforcog_cent + media_wins_1_cent*needforcog_cent + know_cent*needforcog_cent+(1|Score_Type)+(1|ID),   
              data=expertise3_ready)
summary(Model.2.1)

```

This total model is still similar to the single models unlike the interactions between objective expertise and need for cognition. Maybe we don't have enough power to detect these interactions due to sample size. We can still make the similar comments above I guess.


#Winsorize at 1% the raw variables before factor analysis
We can see that there are extreme values for our factor 1 (high+colle) and factor 2 (media+grad). We can deal these values with winsorization:


```{r warning = FALSE, message = FALSE}
# winsorize the variables (at 1%)
expertise3_wins_fact <- expertise3_wins_fact%>%
  mutate(numarticle_w1=Winsorize(numarticle, probs = c(0,0.99)), 
         numbook_w1=Winsorize(numbook, probs = c(0,0.99)),
         high_w1=Winsorize(high, probs = c(0,0.99)),
         colle_w1=Winsorize(colle, probs = c(0,0.99)),
         grad_w1=Winsorize(grad,na.rm=TRUE, probs = c(0,0.99)))

#check descriptives
descriptives(dat=expertise3_wins_fact, vars(high_w1, colle_w1), median=F, n=F, missing=F, sd=T)

descriptives(dat=expertise3_wins_fact, vars(numarticle_w1, numbook_w1, grad_w1), median=F, n=F, missing=F, sd=T)

```

Our minimum and maximum values seems better, let's check histograms:

## Factor analysis with winsorized variables

Factor analysis for expertise variables with raw scores

```{r warning = FALSE, message = FALSE}
# Factor analysis for expertise variables with raw scores ----

# Import packages 

library(psych) #PCA/EFA analysis
library(REdaS) #Produces KMO and Bartletts test
library(GPArotation)


# Create a new dataframe that include only related variables
factor_exp1<-expertise3_wins_fact%>%
  select(colle_w1, grad_w1, high_w1, numarticle_w1, numbook_w1)


# Since grad classes for TV category is missing (nobody takes any class in the sample), listwise deletion is applied here.
bart_spher(factor_exp1, use = "complete.obs") ###### produces Bartletts test of spherecity 

#Check eigenvalues

fa.parallel(factor_exp1)

```

```{r}

# So we can reduce it to 2 factors
fa(factor_exp1, nfactors = 3, rotate =  "oblimin" )  

# Figure for the analysis

M2<-fa(factor_exp1, nfactors = 3, rotate =  "oblimin" ) ##save the analysis as the object m1
fa.diagram(M2,main="Expert Variables")  
```

Eigenvalues suggest 2 components here

### Extracting components
```{r warning = FALSE, message = FALSE}
PrC_expert<- principal(factor_exp1, scores =TRUE, rotate= "varimax", nfactors=2, method="regression")

loadings (PrC_expert)

```


```{r}
#Combining data frames

expertise3_wins_fact1 <- cbind(expertise3_wins_fact, PrC_expert$scores)

```

Check the correlation matrix again, it's the same above:

```{r}
corrMatrix(data = expertise3_wins_fact1, vars = vars(colle_w1, grad_w1, high_w1, numarticle_w1, numbook_w1, RC1, RC2))
```

## Histograms of these components

```{r warning = FALSE, message = FALSE}
##Histogram, descriptives and correlation matrix for new factors ----
descriptives(dat=expertise3_wins_fact1, vars(RC1, RC2),
             sd=T, skew =T)

```

```{r}

hist(expertise3_wins_fact1$RC1)

```

```{r}
hist(expertise3_wins_fact1$RC2)
```


## Long format (with component scores)

Long format of expertise dataset

```{r warning=FALSE, message=FALSE}

library('reshape2')

expertise3_wins_comp <- melt(expertise3_new, id.vars = c("ID",'duration',"sex" ,"education" ,"income","religion",'identity','age','political_atti','english_level','needforcog'), 
                        measure.vars = c("ih_lang", "ih_school","ih_cards", "ih_breakfast", "ih_weddings", 
                                         "ih_teeth", "ih_traffic", "ih_tv",'know_lang','know_school','know_cards','know_breakfast',
                                         'know_weddings','know_teeth','know_traffic','know_tv',
                                         'high_lang', 'colle_lang', 'grad_lang',
                                         'numbook_lang','numarticle_lang',
                                         'high_school', 'colle_school', 'grad_school',
                                         'numbook_school','numarticle_school',
                                         'high_cards', 'colle_cards', 'grad_cards',
                                         'numbook_cards','numarticle_cards',
                                         'high_breakfast', 'colle_breakfast', 'grad_breakfast',
                                         'numbook_breakfast','numarticle_breakfast',
                                         'high_weddings', 'colle_weddings', 'grad_weddings',
                                         'numbook_weddings','numarticle_weddings',
                                         'high_teeth', 'colle_teeth', 'grad_teeth',
                                         'numbook_teeth','numarticle_teeth',
                                         'high_traffic', 'colle_traffic', 'grad_traffic',
                                         'numbook_traffic','numarticle_traffic',
                                         'high_tv', 'colle_tv', 'grad_tv',
                                         'numbook_tv','numarticle_tv'),
                        sep = "_", variable.name = "Category", value.name = "Score")

# Split the Category column into two columns based on the underscore separator
expertise3_wins_comp <- expertise3_wins_comp %>% separate(Category, into = c("Category", "Score_Type"), sep = "_")

## spread the data from long to wide format  ----
expertise3_win1_comp <- expertise3_wins_comp %>% spread(Category, Score)

# change the score type to a factor
expertise3_win1_comp$Score_Type<-as.factor(expertise3_win1_comp$Score_Type)

# convert the column ih to numeric
expertise3_win1_comp$ih<-as.numeric(expertise3_win1_comp$ih)

# Combine factor scores with the final data ----
expertise3_win1_comp<-bind_cols(expertise3_win1_comp,expertise3_wins_fact1$RC1,expertise3_wins_fact1$RC2)

#Rename the combined factor variables
expertise3_win1_comp<-rename(expertise3_win1_comp, PC1=...20)
expertise3_win1_comp<-rename(expertise3_win1_comp, PC2=...21)

```

```{r warning=FALSE, message=FALSE}

# Center variables: 

expertise3_win1_comp$know_cent <- scale(expertise3_win1_comp$know, center = TRUE, scale = FALSE)

expertise3_win1_comp$needforcog_cent <- scale(expertise3_win1_comp$needforcog, center = TRUE, scale = FALSE)

expertise3_win1_comp$PC1_w1_cent <- scale(expertise3_win1_comp$PC1, center = TRUE, scale = FALSE)

expertise3_win1_comp$PC2_w2_cent <- scale(expertise3_win1_comp$PC2, center = TRUE, scale = FALSE)

```


## HLM Models

### Model objective expertise with grad courses, books and magazines

```{r warning = FALSE, message = FALSE}
## Model objective expertise ----

Model_obj<-lmer(ih ~PC1_w1_cent*needforcog_cent+PC1_w1_cent+needforcog_cent+
                (1|Score_Type)+(1|ID), data=expertise3_win1_comp)
summary(Model_obj)


```

### Model objective expertise with high school and college courses


```{r}
Model_obj2<-lmer(ih ~PC2_w2_cent * needforcog_cent +PC2_w2_cent + needforcog_cent+(1|Score_Type)+(1|ID), data=expertise3_win1_comp)
summary(Model_obj2)

```

### Model of perceived expertise and need for cognition


```{r}
Model_perc<-lmer(ih ~know_cent*needforcog_cent+ know_cent + needforcog_cent +
                (1|Score_Type)+(1|ID), data=expertise3_win1_comp)
summary(Model_perc)
```

```{r}
corrMatrix(expertise3_win1_comp,
           vars = vars(know_cent,needforcog_cent), flag = TRUE)
```

### Model of objective expertise, perceived expertise and need for cognition without interaction

```{r}
Model.1.1<-lmer(ih ~PC1_w1_cent + PC2_w2_cent + know_cent +needforcog_cent +(1|Score_Type)+(1|ID),   
              data=expertise3_win1_comp)
summary(Model.1.1)
```

### Model of objective expertise, perceived expertise and need for cognition with interaction

```{r}
Model.2.1<-lmer(ih ~PC1_w1_cent + PC2_w2_cent  + know_cent+needforcog_cent + PC1_w1_cent*needforcog_cent + PC2_w2_cent*needforcog_cent + know_cent*needforcog_cent+(1|Score_Type)+(1|ID),   
              data=expertise3_win1_comp)
summary(Model.2.1)

```


