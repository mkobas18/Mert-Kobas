---
title: "Expertise6 Data Analysis from the very beginning"
author: "MK"
date: "2023-02-23"
categories: [example data, code, analysis]
image: "newdata.png"
---

This post includes the trial analyses of an example data related to expertise.

Notes: Need for closure scores haven't been calculated, the reverse items will be checked. Notes: For the long format, internet article, documentaries and podcast series should be added.

### Import necessary packages and expertise data

```{r warning = FALSE, message = FALSE}
#Import library ----
library(tidyverse)
library(readr)
library(purrr)
library(jmv)
library(psych)
library(DescTools)
library(stats)
library(factoextra)
library(reshape2)
library(lme4) 
library(lmerTest)
library(effects)


#Read the csv file ----
Expertise6 <- read_csv("~/Desktop/Expertise6_5.8.14_December 23, 2022_10.51 2.csv")

```

Creates a new dataframe called expertise6_clean, which is a copy of the original dataframe called expertise6 and removes the second row of the dataframe and create a variable called column_names and assign it the names of the columns in the dataframe and change the column names

```{r warning = FALSE, message = FALSE}

#removes the second row of the dataframe
expertise6_clean<-Expertise6%>% 
  slice(-2) 


#selects all columns except the ones listed 
expertise6_clean <- expertise6_clean %>%
  select(-StartDate, -EndDate, -Status, -Progress,-ResponseId,-RecordedDate,-RecipientLastName, -RecipientFirstName,-RecipientEmail, -ExternalReference, -LocationLatitude,-LocationLongitude, -DistributionChannel, -UserLanguage)

#create a variable called column_names and assign it the names of the columns in the dataframe
column_names <- names(expertise6_clean)

column_names

```

```{r}
##Change the column names ----
colnames(expertise6_clean) <- c('ip','duration', 'finished', 'stih_food','r_ih_food',
                        'stih_sports','r_ih_sports','stih_school','r_ih_school',
                        'stih_architect','r_ih_architect','stih_product','r_ih_product',
                        'stih_langu','r_ih_langu','stih_network','r_ih_network',
                        'stih_anthro','r_ih_anthro',
                        'know_food','know_sports','know_school','know_architect',
                        'know_product','know_langu','know_network','know_anthro',
                        'course_food','high_food', 'colle_food', 'grad_food',
                        'book_food','numbook_food','article_food','numarticle_food',
                        'inarti_food','numinarti_food', 'docu_food', 'numdocu_food',
                        'radio_food','numradio_food',
                        'course_sports','high_sports', 'colle_sports', 'grad_sports',
                        'book_sports','numbook_sports','article_sports','numarticle_sports',
                        'inarti_sports','numinarti_sports', 'docu_sports', 'numdocu_sports',
                        'radio_sports','numradio_sports',
                        'course_school','high_school', 'colle_school', 'grad_school',
                        'book_school','numbook_school','article_school','numarticle_school',
                        'inarti_school','numinarti_school', 'docu_school', 'numdocu_school',
                        'radio_school','numradio_school',
                        'course_architect','high_architect', 'colle_architect','grad_architect',
                        'book_architect','numbook_architect','article_architect',
                        'numarticle_architect',
                        'inarti_architect','numinarti_architect', 
                        'docu_architect', 'numdocu_architect',
                        'radio_architect','numradio_architect',
                        'course_product','high_product', 'colle_product', 'grad_product',
                        'book_product','numbook_product','article_product',
                        'numarticle_product',
                        'inarti_product','numinarti_product', 'docu_product', 'numdocu_product',
                        'radio_product','numradio_product',
                        'course_langu','high_langu', 'colle_langu', 'grad_langu',
                        'book_langu','numbook_langu','article_langu','numarticle_langu',
                        'inarti_langu','numinarti_langu', 'docu_langu', 'numdocu_langu',
                        'radio_langu','numradio_langu',
                        'course_network','high_network', 'colle_network', 'grad_network',
                        'book_network','numbook_network','article_network','numarticle_network',
                        'inarti_network','numinarti_network', 'docu_network', 'numdocu_network',
                        'radio_network','numradio_network',
                        'course_anthro','high_anthro', 'colle_anthro', 'grad_anthro',
                        'book_anthro','numbook_anthro','article_anthro','numarticle_anthro',
                        'inarti_anthro','numinarti_anthro', 'docu_anthro', 'numdocu_anthro',
                        'radio_anthro','numradio_anthro',
                        'needforclo1','needforclo2','needforclo3','needforclo4','needforclo5',
                        'needforclo6','needforclo7','needforclo8','needforclo9','needforclo10',
                        'needforclo11','needforclo12','needforclo13','needforclo14',
                        'needforclo15','needforclo16','needforclo17','needforclo18',
                        'needforclo19','needforclo20','needforclo21','needforclo22',
                        'needforclo23','needforclo24','needforclo25','needforclo26',
                        'needforclo27','needforclo28','needforclo29','needforclo30',
                        'needforclo31','needforclo32','needforclo33','needforclo34',
                        'needforclo35','needforclo36','needforclo37','needforclo38',
                        'needforclo39','needforclo40','needforclo41','needforclo42',
                        'sex','birthdate','education','income','religion',
                        'identity','age','political_atti','english_level','proceure_confu',
                        'whatwestudied','moretothisstudy','additional_thoughts','attention', 
                        'surveyorder')


```

### Questionnaire Items

The code below shows the survey items:

```{r warning = FALSE, message = FALSE}

#selects all columns except the ones specified
row_values <- expertise6_clean %>%
  select(-duration,-finished, -ip, -surveyorder)%>%
  #selects only the first row
  filter(row_number() == 1)

#Items in the questionnaire ----

#unlist the row_values
row_values <- unlist(row_values)

my_list <- map(row_values, ~paste0(.))

library(stringr)
my_list <- str_replace(my_list, "(?<! )\\n(?! )", "")
my_list <- str_replace(my_list, "[^\\s]*\\\\n[^\\s]*", "")
list_string <- paste0("* ", paste(my_list, collapse = "\n* "))

##Show the survey items ----
cat(list_string)
```

### Exclusion Criterias

Data preparation for further analyses

```{r warning = FALSE, message = FALSE}

#Attention check and deletion of cases that didn't attend or finish the study ----
expertise6_new<-expertise6_clean%>%
  filter(attention==1&finished==1)

##Exclude the participants that joined outside of US ----

#view(expertise6_new)
expertise6_new<-expertise6_new%>%
  filter(ip!="66.42.251.231")

expertise6_new <- expertise6_new %>%
  filter(!(ip %in% c("74.219.142.226", "24.12.92.17", "184.88.52.194", 
                     "97.103.220.145", "76.250.238.38")))

##selecting the columns that we want to keep ----
expertise6_new<-expertise6_new%>%
  select(-finished,-birthdate,-proceure_confu,-whatwestudied,-moretothisstudy,-additional_thoughts,-attention, -surveyorder)

#adds a column to the dataframe, with the name "id"
expertise6_new<-cbind(ID = 1:nrow(expertise6_new), expertise6_new)

# Numeric variables ----
# Change the data type of the variables to numeric 
expertise6_new <- expertise6_new %>%
  mutate_at(vars(stih_food, r_ih_food, stih_sports, r_ih_sports, stih_school, r_ih_school, stih_architect, r_ih_architect, 
                 stih_product, r_ih_product, stih_langu, r_ih_langu, stih_network, r_ih_network, stih_anthro, r_ih_anthro), as.numeric)


```

## Correlation for ih scores

Check the correlations between inherence (the variables starting with st) and reverse inherence (the variables starting with r) scores to check whether it's appropriate for averaging

```{r warning = FALSE, message = FALSE}

# Correlations between ih scores ----

# Create a list of variable names
variables <- c("stih_food", "r_ih_food", "stih_sports", "r_ih_sports", "stih_school", "r_ih_school", "stih_architect", "r_ih_architect", "stih_product", "r_ih_product", "stih_langu", "r_ih_langu", "stih_network", "r_ih_network", "stih_anthro", "r_ih_anthro")

# Initialize an empty data frame to store the correlation coefficients
correlations <- data.frame(variable1 = character(), variable2 = character(), correlation = numeric(), p.value = numeric(), conf.int = character())

# Iterate over the pairs of variables
for (i in seq(1, length(variables), 2)) {
  j <- i + 1
  
  # Calculate the Pearson correlation coefficient and test the statistical significance
  correlation_test <- cor.test(expertise6_new[, variables[i]], expertise6_new[, variables[j]], method = "pearson")
  
  # Add the correlation coefficient, p-value, and confidence interval to the data frame
  correlations <- rbind(correlations, data.frame(variable1 = variables[i], variable2 = variables[j], correlation = correlation_test$estimate, p.value = correlation_test$p.value, conf.int = paste(correlation_test$conf.int[1], correlation_test$conf.int[2], sep = " - ")))}

## View the correlation coefficients and statistical measures ----
correlations
```

## IH scores calculation

It seems that each pairs have negative significant correlation, so we can take the average scores to calculate inherence scores

```{r warning = FALSE, message = FALSE}

## Average of ih scores  ----
#It seems that each pairs have negative significant correlation, so we can take the average scores to measure inherence scores
expertise6_new <- expertise6_new %>%
  mutate(ih_food = (stih_food + (10 - r_ih_food))/2,
         ih_sports = (stih_sports + (10 - r_ih_sports)) / 2,
         ih_school = (stih_school + (10 - r_ih_school)) / 2,
         ih_architect = (stih_architect + (10 - r_ih_architect)) / 2,
         ih_product = (stih_product + (10 - r_ih_product)) / 2,
         ih_langu = (stih_langu + (10 - r_ih_langu)) / 2,
         ih_network = (stih_network + (10-r_ih_network)) / 2,
         ih_anthro = (stih_anthro + (10-r_ih_anthro)) / 2 )

```

## Need for Cognition scores calculation

Calculate "Need for cognition" scale scores

```{r warning = FALSE, message = FALSE}
# Need for cognition scale scores  ----

# change the data type of the variables to numeric
expertise6_new <- expertise6_new %>%
  mutate_at(vars( 'needforclo1','needforclo2','needforclo3','needforclo4','needforclo5',
                        'needforclo6','needforclo7','needforclo8','needforclo9','needforclo10',
                        'needforclo11','needforclo12','needforclo13','needforclo14',
                        'needforclo15','needforclo16','needforclo17','needforclo18',
                        'needforclo19','needforclo20','needforclo21','needforclo22',
                        'needforclo23','needforclo24','needforclo25','needforclo26',
                        'needforclo27','needforclo28','needforclo29','needforclo30',
                        'needforclo31','needforclo32','needforclo33','needforclo34',
                        'needforclo35','needforclo36','needforclo37','needforclo38',
                        'needforclo39','needforclo40','needforclo41','needforclo42'), as.numeric)

## Calculate needforclo scores  ----
#add a new variable called needforclo, which is the sum of all the need for cognition items, the items are weighted according to the scoring key
expertise6_new <- expertise6_new %>%
  group_by(ID)%>%
  mutate(needforclo=(needforclo1+needforclo2+needforclo3+needforclo4+
                       (10-needforclo5)+needforclo6+needforclo7+(10-needforclo8)+
                       (10-needforclo9)+needforclo10+ needforclo11+needforclo12+
                       needforclo13+needforclo14+needforclo15+needforclo16+
                       needforclo17+needforclo18+needforclo19+(10-needforclo20)+
                       (10-needforclo21)+(10-needforclo22)+needforclo23+(10-needforclo24)+
                       (10-needforclo25)+needforclo26+needforclo27+(10-needforclo28)+
                       needforclo29+needforclo30+(10-needforclo31)+(10-needforclo32)+
                       needforclo33+needforclo34+needforclo35+(10-needforclo36)+
                       needforclo37+(10-needforclo38)+needforclo39+(10-needforclo40)+
                       (10-needforclo41)+needforclo42)/42)
```

## Data preparation

Prepare the expertise scores and other scores ready for analyses

```{r warning = FALSE, message = FALSE}

# Replace expertise variables' NA values in the expertise columns with 0  ----
variables <- c('know_food','know_sports','know_school','know_architect',
                        'know_product','know_langu','know_network','know_anthro',
                        'high_food', 'colle_food', 'grad_food',
                        'numbook_food','numarticle_food',
                        'numinarti_food', 'numdocu_food',
                        'numradio_food',
                        'high_sports', 'colle_sports', 'grad_sports',
                        'numbook_sports','numarticle_sports',
                        'numinarti_sports', 'numdocu_sports',
                        'numradio_sports',
                        'high_school', 'colle_school', 'grad_school',
                        'numbook_school','numarticle_school',
                        'numinarti_school','numdocu_school',
                        'numradio_school',
                        'high_architect', 'colle_architect','grad_architect',
                        'numbook_architect',
                        'numarticle_architect',
                        'numinarti_architect', 
                        'numdocu_architect',
                        'numradio_architect',
                        'high_product', 'colle_product', 'grad_product',
                        'numbook_product',
                        'numarticle_product',
                       'numinarti_product','numdocu_product',
                        'numradio_product',
                        'high_langu', 'colle_langu', 'grad_langu',
                        'numbook_langu','numarticle_langu',
                        'numinarti_langu', 'numdocu_langu',
                        'numradio_langu',
                        'high_network', 'colle_network', 'grad_network',
                        'numbook_network','numarticle_network',
                        'numinarti_network', 'numdocu_network',
                        'numradio_network',
                        'high_anthro', 'colle_anthro','grad_anthro',
                        'numbook_anthro','numarticle_anthro',
                        'numinarti_anthro', 'numdocu_anthro',
                        'numradio_anthro')

expertise6_new <- expertise6_new %>%
  mutate_at(vars('know_food','know_sports','know_school','know_architect',
                        'know_product','know_langu','know_network','know_anthro',
                        'high_food', 'colle_food', 'grad_food',
                        'numbook_food','numarticle_food',
                        'numinarti_food', 'numdocu_food',
                        'numradio_food',
                        'high_sports', 'colle_sports', 'grad_sports',
                        'numbook_sports','numarticle_sports',
                        'numinarti_sports', 'numdocu_sports',
                        'numradio_sports',
                        'high_school', 'colle_school', 'grad_school',
                        'numbook_school','numarticle_school',
                        'numinarti_school','numdocu_school',
                        'numradio_school',
                        'high_architect', 'colle_architect','grad_architect',
                        'numbook_architect',
                        'numarticle_architect',
                        'numinarti_architect', 
                        'numdocu_architect',
                        'numradio_architect',
                        'high_product', 'colle_product', 'grad_product',
                        'numbook_product',
                        'numarticle_product',
                       'numinarti_product','numdocu_product',
                        'numradio_product',
                        'high_langu', 'colle_langu', 'grad_langu',
                        'numbook_langu','numarticle_langu',
                        'numinarti_langu', 'numdocu_langu',
                        'numradio_langu',
                        'high_network', 'colle_network', 'grad_network',
                        'numbook_network','numarticle_network',
                        'numinarti_network', 'numdocu_network',
                        'numradio_network',
                        'high_anthro', 'colle_anthro','grad_anthro',
                        'numbook_anthro','numarticle_anthro',
                        'numinarti_anthro', 'numdocu_anthro',
                        'numradio_anthro'), as.numeric)


#expertise6_new[variables] <- lapply(expertise6_new[variables], 
                                    #function(x) ifelse(is.na(x), 0, ifelse(x=='no',0, x)))

expertise6_new[variables] <- lapply(expertise6_new[variables], function(x) replace(x, is.na(x) | !is.numeric(x) , 0))


```

## Detect the ID of missing values of expertise scores

```{r}
missing_ids <- unlist(mapply(function(x) expertise6_new$ID[which(is.na(expertise6_new[x]))], c('know_food','know_sports','know_school','know_architect',
                        'know_product','know_langu','know_network','know_anthro',
                        'high_food', 'colle_food', 'grad_food',
                        'numbook_food','numarticle_food',
                        'numinarti_food', 'numdocu_food',
                        'numradio_food',
                        'high_sports', 'colle_sports', 'grad_sports',
                        'numbook_sports','numarticle_sports',
                        'numinarti_sports', 'numdocu_sports',
                        'numradio_sports',
                        'high_school', 'colle_school', 'grad_school',
                        'numbook_school','numarticle_school',
                        'numinarti_school','numdocu_school',
                        'numradio_school',
                        'high_architect', 'colle_architect','grad_architect',
                        'numbook_architect',
                        'numarticle_architect',
                        'numinarti_architect', 
                        'numdocu_architect',
                        'numradio_architect',
                        'high_product', 'colle_product', 'grad_product',
                        'numbook_product',
                        'numarticle_product',
                       'numinarti_product','numdocu_product',
                        'numradio_product',
                        'high_langu', 'colle_langu', 'grad_langu',
                        'numbook_langu','numarticle_langu',
                        'numinarti_langu', 'numdocu_langu',
                        'numradio_langu',
                        'high_network', 'colle_network', 'grad_network',
                        'numbook_network','numarticle_network',
                        'numinarti_network', 'numdocu_network',
                        'numradio_network',
                        'high_anthro', 'colle_anthro','grad_anthro',
                        'numbook_anthro','numarticle_anthro',
                        'numinarti_anthro', 'numdocu_anthro',
                        'numradio_anthro')))

cat(ifelse(length(missing_ids[missing_ids > 0]) > 0, paste("The following IDs are missing:",missing_ids[missing_ids != 0]), "There is no missing IDs."),"\n")
```

```{r}

# Expertise Ready Df ----

#','high_food','colle_food','grad_food','numbook_food','numarticle_food','numinarti_food','numdocu_food','numradio_food','high_sports','colle_sports','grad_sports','numbook_sports','numarticle_sports','numinarti_sports','numdocu_sports','numradio_sports','high_school','colle_school','grad_school','numbook_school','numarticle_school','numinarti_school','numdocu_school','numradio_school','high_architect','colle_architect','grad_architect','numbook_architect','numarticle_architect','numinarti_architect','numdocu_architect','numradio_architect','high_product','colle_product','grad_product','numbook_product','numarticle_product','numinarti_product','numdocu_product','numradio_product','high_langu','colle_langu','grad_langu','numbook_langu','numarticle_langu','numinarti_langu','numdocu_langu','numradio_langu','high_network','colle_network','grad_network','numbook_network','numarticle_network','numinarti_network','numdocu_network','numradio_network','high_anthro','colle_anthro','grad_anthro','numbook_anthro','numarticle_anthro','numinarti_anthro','numdocu_anthro','numradio_anthro

# change the data type of the variables to numeric
expertise6_new<-expertise6_new%>%mutate_at(vars('know_food','know_sports','know_school','know_architect','know_product','know_langu','know_network','know_anthro'),as.numeric)


```

## Long format

Long format of expertise dataset for factor analysis

```{r warning = FALSE, message = FALSE}

expertise6_factor <- melt(expertise6_new, id.vars = c("ID",'duration',"sex" ,"education" ,"income","religion",'identity','age','political_atti','english_level','needforclo'), 
                        measure.vars = c("ih_food", "ih_sports","ih_school","ih_architect",
                                         "ih_product","ih_langu","ih_network","ih_anthro",
                       'know_food','know_sports','know_school','know_architect',
                        'know_product','know_langu','know_network','know_anthro',
                        'high_food', 'colle_food', 'grad_food',
                        'numbook_food','numarticle_food',
                        'numinarti_food', 'numdocu_food',
                        'numradio_food',
                        'high_sports', 'colle_sports', 'grad_sports',
                        'numbook_sports','numarticle_sports',
                        'numinarti_sports', 'numdocu_sports',
                        'numradio_sports',
                        'high_school', 'colle_school', 'grad_school',
                        'numbook_school','numarticle_school',
                        'numinarti_school','numdocu_school',
                        'numradio_school',
                        'high_architect', 'colle_architect','grad_architect',
                        'numbook_architect',
                        'numarticle_architect',
                        'numinarti_architect', 
                        'numdocu_architect',
                        'numradio_architect',
                        'high_product', 'colle_product', 'grad_product',
                        'numbook_product',
                        'numarticle_product',
                       'numinarti_product','numdocu_product',
                        'numradio_product',
                        'high_langu', 'colle_langu', 'grad_langu',
                        'numbook_langu','numarticle_langu',
                        'numinarti_langu', 'numdocu_langu',
                        'numradio_langu',
                        'high_network', 'colle_network', 'grad_network',
                        'numbook_network','numarticle_network',
                        'numinarti_network', 'numdocu_network',
                        'numradio_network',
                        'high_anthro', 'colle_anthro','grad_anthro',
                        'numbook_anthro','numarticle_anthro',
                        'numinarti_anthro', 'numdocu_anthro',
                        'numradio_anthro'),
                        sep = "_", variable.name = "Category", value.name = "Score")

# Split the Category column into two columns based on the underscore separator
expertise6_factor <- expertise6_factor %>% separate(Category, into = c("Category", "Score_Type"), sep = "_")

## spread the data from long to wide format  ----
expertise6_fact <- expertise6_factor %>% spread(Category, Score)

# change the score type to a factor
expertise6_fact$Score_Type<-as.factor(expertise6_fact$Score_Type)

# convert the column ih to numeric
expertise6_fact$ih<-as.numeric(expertise6_fact$ih)
```

###Create another data frame to winsorize expertise variables before factor analysis

```{r}
expertise6_wins_fact<-expertise6_fact

```

## Winsorize the variables at 1%

```{r warning = FALSE, message = FALSE}
# winsorize the variables (at 1%)
expertise6_fact1 <- expertise6_fact%>%
  mutate(numarticle=Winsorize(numarticle, probs = c(0,0.99)), 
         numbook=Winsorize(numbook, probs = c(0,0.99)),
         high=Winsorize(high, probs = c(0,0.99)),
         colle=Winsorize(colle, probs = c(0,0.99)),
         grad=Winsorize(grad,na.rm=TRUE, probs = c(0,0.99)),
         numdocu=Winsorize(numdocu,na.rm=TRUE, probs = c(0,0.99)),
         numinarti=Winsorize(numinarti,na.rm=TRUE, probs = c(0,0.99)),
         numradio=Winsorize(numradio,na.rm=TRUE, probs = c(0,0.99)))

```

## Factor analysis

```{r}
# Factor analysis for expertise variables with raw scores ----

# Import packages 

library(psych) #PCA/EFA analysis
library(REdaS) #Produces KMO and Bartletts test
library(GPArotation)


# Create a new dataframe that include only related variables
factor_exp<-expertise6_fact1%>%
  select(colle, grad, high, numarticle, numbook, numdocu, numinarti, numradio)

# Check missing values
apply(is.na(factor_exp), 2, sum)



```

Factor analysis for expertise variables with raw scores

```{r warning = FALSE, message = FALSE}

# Since grad classes for TV category is missing (nobody takes any class in the sample), listwise deletion is applied here.
bart_spher(factor_exp, use = "complete.obs") ###### produces Bartletts test of spherecity 

KMO(factor_exp)       ###### Kaiser-Meyer-Olkin measure, which is above .5.

#Check eigenvalues

fa.parallel(factor_exp)


```

### Factor analysis

```{r}

# So we can reduce it to 2 factors
fa(factor_exp, nfactors = 2, rotate =  "oblimin" )  

# Figure for the analysis

M1<-fa(factor_exp, nfactors = 2, rotate =  "oblimin" ) ##save the analysis as the object m1
fa.diagram(M1,main="Expertise Variables")  

```

So here we have two factors and we can investigate them as classes and media-literature part, let's extract values for now, but creating these categories with averaging related variables may be a better way for the sake of conceptual understanding.

### Extracting factor values

```{r warning = FALSE, message = FALSE}
factor_exp_score <- factanal(factor_exp, factors=2, scores="regression", rotation = "oblimin", na.rm=TRUE)

head(factor_exp_score$scores)

factor_exp_comb <- bind_cols(factor_exp, data.frame(factor_exp_score$scores))

factor_exp_comb$class<-factor_exp_comb$Factor1

factor_exp_comb$media_grad<-factor_exp_comb$Factor2

```

### Histogram and descriptives for factor scores

```{r warning = FALSE, message = FALSE}
descriptives(dat=factor_exp_comb, vars(Factor1, Factor2),
             sd=T)

```

```{r warning = FALSE, message = FALSE}
hist(factor_exp_comb$Factor1)

```

```{r warning = FALSE, message = FALSE}
hist(factor_exp_comb$Factor2)
```

## Winsorize the variables at 1%

```{r warning = FALSE, message = FALSE}
# winsorize the variables (at 1%)
expertise6_ready <- expertise6_fact%>%
  mutate(numarticle_wins_1=Winsorize(numarticle, probs = c(0,0.99)), 
         numbook_wins_1=Winsorize(numbook, probs = c(0,0.99)),
         high_wins_1=Winsorize(high, probs = c(0,0.99)),
         colle_wins_1=Winsorize(colle, probs = c(0,0.99)),
         grad_wins_1=Winsorize(grad,na.rm=TRUE, probs = c(0,0.99)),
         docu_wins_1=Winsorize(numdocu,na.rm=TRUE, probs = c(0,0.99)),
         inarti_wins_1=Winsorize(numinarti,na.rm=TRUE, probs = c(0,0.99)),
         radio_wins_1=Winsorize(numradio,na.rm=TRUE, probs = c(0,0.99)))

#check descriptives
descriptives(dat=expertise6_ready, vars(docu_wins_1,inarti_wins_1, radio_wins_1 ), median=F, n=F, missing=T, sd=T, skew =T)

descriptives(dat=expertise6_ready, vars(high_wins_1, colle_wins_1), median=F, n=F, missing=T, sd=T)

descriptives(dat=expertise6_ready, vars(numarticle_wins_1, numbook_wins_1, grad_wins_1), median=F, n=F, missing=T, sd=T)


```

```{r warning = FALSE, message = FALSE}
# Standardize the Selected variables  ----
vars_to_standardize <- c("know", "docu_wins_1","inarti_wins_1", "radio_wins_1","high_wins_1", "colle_wins_1",
                         "numarticle_wins_1", "numbook_wins_1", "grad_wins_1")



expertise6_ready<-expertise6_ready %>% 
  group_by(Score_Type) %>% 
  mutate_at(vars(vars_to_standardize), scale)

```

```{r warning = FALSE, message = FALSE}
sum(is.na(expertise6_ready$grad_wins_1))


```

## Take the means of winsorized variables to create our new categories: media and class

```{r warning = FALSE, message = FALSE}
expertise6_ready <- expertise6_ready %>% replace_na(list(colle_wins_1 = NA, high_wins_1 = NA, grad_wins_1 = NA, docu_wins_1= NA,inarti_wins_1 = NA, radio_wins_1 = NA, numarticle_wins_1 = NA, numbook_wins_1 = NA))


expertise6_ready <- expertise6_ready %>% mutate(class_wins1 = mapply(function(x, y, z) {
  ifelse(is.na(x), (y + z)/2, 
         ifelse(is.na(y), (x + z)/2, 
                ifelse(is.na(z), (x + y)/2, (x + y + z)/3)))}, 
  grad_wins_1, colle_wins_1, high_wins_1))

expertise6_ready <- expertise6_ready %>% mutate(media_wins1 = mapply(function(x, y, z, t, r) {
  ifelse(is.na(x), (y + z + t + r)/4, 
         ifelse(is.na(y), (x + z + t + r)/4,
                ifelse(is.na(z), (x + y + t + r)/4, 
                       ifelse(is.na(t),(x + y + z + r)/4, 
                              ifelse(is.na(r),(x + y + z + t)/4,
                                     (x + y + z + t + r)/5)))))}, 
  docu_wins_1,inarti_wins_1, radio_wins_1, numbook_wins_1, numarticle_wins_1))

```

## Center the variables

```{r warning = FALSE, message = FALSE}

expertise6_ready$know_cent <- scale(expertise6_ready$know, center = TRUE, scale = FALSE)

expertise6_ready$needforclo_cent <- scale(expertise6_ready$needforclo, center = TRUE, scale = FALSE)

expertise6_ready$class_wins1_cent <- scale(expertise6_ready$class_wins1, center = TRUE, scale = FALSE)

expertise6_ready$media_wins1_cent <- scale(expertise6_ready$media_wins1, center = TRUE, scale = FALSE)

```

Descriptives

```{r}

describe(expertise6_ready)

```

##Shapiro-Wilk values

```{r warning = FALSE, message = FALSE}
descriptives(expertise6_ready, vars = vars(class_wins1, media_wins1, know, ih),n=FALSE, missing= FALSE, median=FALSE, sw = TRUE)

write.csv(expertise6_ready, '/Users/mertkobas/Desktop/expert6_wins_average.csv')
```

## HLM Models

### Model objective expertise with grad courses, books and magazines

```{r warning = FALSE, message = FALSE}
## Model objective expertise ----

Model_obj<-lmer(ih ~class_wins1_cent*needforclo_cent+class_wins1_cent+needforclo_cent+
                (1|Score_Type)+(1|ID), data=expertise6_ready)
summary(Model_obj)


```

### Model objective expertise with high school and college courses

```{r}
Model_obj2<-lmer(ih ~media_wins1_cent * needforclo_cent +media_wins1_cent + needforclo_cent+(1|Score_Type)+(1|ID), data=expertise6_ready)
summary(Model_obj2)

```

### Model of perceived expertise and need for cognition

```{r}
Model_perc<-lmer(ih ~know_cent*needforclo_cent+ know_cent + needforclo_cent +
                (1|Score_Type)+(1|ID), data=expertise6_ready)
summary(Model_perc)
```

### Model of objective expertise, perceived expertise and need for cognition without interaction

```{r}
options(scipen=999)
Model.1.1<-lmer(ih ~class_wins1_cent + media_wins1_cent + know_cent +needforclo_cent +(1|Score_Type)+(1|ID),   
              data=expertise6_ready)
summary(Model.1.1)
```

### Model of objective expertise, perceived expertise and need for cognition with interaction

```{r}
Model.2.1<-lmer(ih ~class_wins1_cent + media_wins1_cent  + know_cent+ needforclo_cent +
                  class_wins1_cent*needforclo_cent + media_wins1_cent*needforclo_cent +
                  +(1|Score_Type)+(1|ID),data=expertise6_ready)
summary(Model.2.1)

```

#Plot of the model 1.1

```{r warning = FALSE, message = FALSE}
Model.1.1 <- lmer(ih ~class_wins1_cent + media_wins1_cent + know_cent +needforclo_cent +(1|Score_Type)+(1|ID),   
              data=expertise6_ready)
summary(Model.1.1)
# save fitted data
ef.1.media <- effect(term = "media_wins1_cent",
                                   mod = Model.1.1)
ef.1.media.data <- as.data.frame(ef.1.media) #convert the effects list to a data frame
ef.1.media.data #print effects data frame

expert_media_graph <- expertise6_ready %>%
  group_by(ID) %>%
  summarise(ih = mean(ih),
            media_wins1_cent = media_wins1)
expert_media_graph <- as.data.frame(expert_media_graph)

expert_media_graph$media_wins1_cent<-expert_media_graph$media_wins1_cent-min(expert_media_graph$media_wins1_cent)
```

```{r warning = FALSE, message = FALSE}
tab_model(Model.1.1, file = "expertise6_model1.1_w1.doc")

```

```{r warning = FALSE, message = FALSE}
fig.1.expert6_w1 <- ggplot(data = ef.1.media.data, aes(x = media_wins1_cent,
                                                  y = fit)) +
  geom_point(data=expert_media_graph, aes(x=media_wins1_cent,y=ih),
             show.legend = FALSE, pch=21, color="blueviolet", alpha=.25, size=3) +
  geom_line(aes(x=media_wins1_cent), color = "darkred", size = 1.2)  +
  geom_ribbon(aes(ymin = fit-se, ymax = fit+se), alpha = 0.50, fill = "gray70") +
  labs(title = "Expertise and Inherence Bias", x = "Expertise (books,articles)",
       y = "Inherence bias") +
  scale_x_continuous(limits = c(0, 8), breaks = seq(0, 8, 2), expand = c(0, 0)) +
  scale_y_continuous(limits = c(0, 10), breaks = seq(0, 10, 2), expand = c(0, 0)) +
  theme_classic() +
  theme(plot.title = element_blank(),
        axis.title = element_text(size = 25, face = "bold"),
        axis.text = element_text(size = 18),
        legend.title = element_blank(),
        panel.grid = element_blank(),
        panel.border = element_blank(),
        plot.background=element_rect(fill = "gray96"),
        panel.background = element_rect(fill = "gray96"))
fig.1.expert6_w1

ggsave(paste0("figure_expertise6+media_w1",
              format(Sys.time(), "%Y-%m-%d")
              ,".png"), width = 25, height = 20, units = "cm") ###Save the Figure 3C

```

## Winsorize the variables at 2.5%

```{r warning = FALSE, message = FALSE}
# winsorize the variables (at 2.5%)
expertise6_readyw25 <- expertise6_fact%>%
  mutate(numarticle_wins_1=Winsorize(numarticle, probs = c(0,0.975)), 
         numbook_wins_1=Winsorize(numbook, probs = c(0,0.975)),
         high_wins_1=Winsorize(high, probs = c(0,0.975)),
         colle_wins_1=Winsorize(colle, probs = c(0,0.975)),
         grad_wins_1=Winsorize(grad,na.rm=TRUE, probs = c(0,0.975)),
         docu_wins_1=Winsorize(numdocu,na.rm=TRUE, probs = c(0,0.975)),
         inarti_wins_1=Winsorize(numinarti,na.rm=TRUE, probs = c(0,0.975)),
         radio_wins_1=Winsorize(numradio,na.rm=TRUE, probs = c(0,0.975)))

#check descriptives
descriptives(dat=expertise6_readyw25, vars(docu_wins_1,inarti_wins_1, radio_wins_1 ), median=F, n=F, missing=T, sd=T, skew =T)

descriptives(dat=expertise6_readyw25, vars(high_wins_1, colle_wins_1), median=F, n=F, missing=T, sd=T)

descriptives(dat=expertise6_readyw25, vars(numarticle_wins_1, numbook_wins_1, grad_wins_1), median=F, n=F, missing=T, sd=T)

```

```{r warning = FALSE, message = FALSE}
# Standardize the Selected variables  ----
vars_to_standardize <- c("know", "docu_wins_1","inarti_wins_1", "radio_wins_1","high_wins_1", "colle_wins_1",
                         "numarticle_wins_1", "numbook_wins_1", "grad_wins_1")



expertise6_readyw25<-expertise6_readyw25 %>% 
  group_by(Score_Type) %>% 
  mutate_at(vars(vars_to_standardize), scale)

```

```{r warning = FALSE, message = FALSE}
sum(is.na(expertise6_readyw25$grad_wins_1))


```

## Take the means of winsorized variables to create our new categories: media and class

```{r warning = FALSE, message = FALSE}
expertise6_readyw25 <- expertise6_readyw25 %>% replace_na(list(colle_wins_1 = NA, high_wins_1 = NA, grad_wins_1 = NA, docu_wins_1= NA,inarti_wins_1 = NA, radio_wins_1 = NA, numarticle_wins_1 = NA, numbook_wins_1 = NA))


expertise6_readyw25 <- expertise6_readyw25 %>% mutate(class_wins1 = mapply(function(x, y, z) {
  ifelse(is.na(x), (y + z)/2, 
         ifelse(is.na(y), (x + z)/2, 
                ifelse(is.na(z), (x + y)/2, (x + y + z)/3)))}, 
  grad_wins_1, colle_wins_1, high_wins_1))

expertise6_readyw25 <- expertise6_readyw25 %>% mutate(media_wins1 = mapply(function(x, y, z, t, r) {
  ifelse(is.na(x), (y + z + t + r)/4, 
         ifelse(is.na(y), (x + z + t + r)/4,
                ifelse(is.na(z), (x + y + t + r)/4, 
                       ifelse(is.na(t),(x + y + z + r)/4, 
                              ifelse(is.na(r),(x + y + z + t)/4,
                                     (x + y + z + t + r)/5)))))}, 
  docu_wins_1,inarti_wins_1, radio_wins_1, numbook_wins_1, numarticle_wins_1))

```

## Center the variables

```{r warning = FALSE, message = FALSE}

expertise6_readyw25$know_cent <- scale(expertise6_readyw25$know, center = TRUE, scale = FALSE)

expertise6_readyw25$needforclo_cent <- scale(expertise6_readyw25$needforclo, center = TRUE, scale = FALSE)

expertise6_readyw25$class_wins1_cent <- scale(expertise6_readyw25$class_wins1, center = TRUE, scale = FALSE)

expertise6_readyw25$media_wins1_cent <- scale(expertise6_readyw25$media_wins1, center = TRUE, scale = FALSE)

```

##Shapiro-Wilk values

```{r warning = FALSE, message = FALSE}
descriptives(expertise6_readyw25, vars = vars(class_wins1, media_wins1, know, ih),n=FALSE, missing= FALSE, median=FALSE, sw = TRUE)
```

## HLM Models

### Model of objective expertise, perceived expertise and need for cognition without interaction

```{r}
Model.1.1<-lmer(ih ~class_wins1_cent + media_wins1_cent + know_cent +needforclo_cent +(1|Score_Type)+(1|ID),   
              data=expertise6_readyw25)
summary(Model.1.1)
```

#Plot of the model 1.1

```{r warning = FALSE, message = FALSE}
Model.1.1 <- lmer(ih ~class_wins1_cent + media_wins1_cent + know_cent +needforclo_cent +(1|Score_Type)+(1|ID),   
              data=expertise6_readyw25)
summary(Model.1.1)
# save fitted data
ef.1.media <- effect(term = "media_wins1_cent",
                                   mod = Model.1.1)
ef.1.media.data <- as.data.frame(ef.1.media) #convert the effects list to a data frame
ef.1.media.data #print effects data frame

expert_media_graph <- expertise6_readyw25 %>%
  group_by(ID) %>%
  summarise(ih = mean(ih),
            media_wins1_cent = media_wins1)
expert_media_graph <- as.data.frame(expert_media_graph)

expert_media_graph$media_wins1_cent<-expert_media_graph$media_wins1_cent-min(expert_media_graph$media_wins1_cent)
```

```{r warning = FALSE, message = FALSE}
fig.1.expert6_w1 <- ggplot(data = ef.1.media.data, aes(x = media_wins1_cent,
                                                  y = fit)) +
  geom_point(data=expert_media_graph, aes(x=media_wins1_cent,y=ih),
             show.legend = FALSE, pch=21, color="blueviolet", alpha=.25, size=3) +
  geom_line(aes(x=media_wins1_cent), color = "darkred", size = 1.2)  +
  geom_ribbon(aes(ymin = fit-se, ymax = fit+se), alpha = 0.50, fill = "gray70") +
  labs(title = "Expertise and Inherence Bias", x = "Expertise (informational sources)",
       y = "Inherence bias") +
  scale_x_continuous(limits = c(0, 6), breaks = seq(0, 6, 2), expand = c(0, 0)) +
  scale_y_continuous(limits = c(0, 10), breaks = seq(0, 8, 2), expand = c(0, 0)) +
  theme_classic() +
  theme(plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
        axis.title = element_text(size = 14, face = "bold"),
        axis.text = element_text(size = 12),
        legend.title = element_blank(),
        panel.grid = element_blank(),
        panel.border = element_blank(),
        #plot.background=element_rect(fill = "gray96"),
       # panel.background = element_rect(fill = "gray96")
       )
fig.1.expert6_w1

ggsave(paste0("figure_expertise6+media_w25",
              format(Sys.time(), "%Y-%m-%d")
              ,".eps"), width = 20, height = 20, units = "cm") ###Save the Figure

```

#Sqrt variables

##Square root of the raw variables for our new expertise variables

```{r warning = FALSE, message = FALSE}
# take the square root of the variables
expertise6_sqrt <- expertise6_fact%>%
  mutate(numarticle_sqrt=sqrt(numarticle),
         numbook_sqrt=sqrt(numbook),
         high_sqrt=sqrt(high),
         colle_sqrt=sqrt(colle),
         grad_sqrt=sqrt(grad),
         docu_sqrt=sqrt(numdocu),
         inarti_sqrt=sqrt(numinarti),
         radio_sqrt=sqrt(numradio))

```

```{r warning = FALSE, message = FALSE}
# Standardize the Selected variables  ----
vars_to_standardize <- c("know", "docu_sqrt","inarti_sqrt", "radio_sqrt","high_sqrt", "colle_sqrt",
                         "numarticle_sqrt", "numbook_sqrt", "grad_sqrt")



expertise6_sqrt<-expertise6_sqrt %>% 
  group_by(Score_Type) %>% 
  mutate_at(vars(vars_to_standardize), scale)

```

## Take the means of winsorized variables to create our new categories: media and class

```{r warning = FALSE, message = FALSE}

expertise6_sqrt <- expertise6_sqrt %>% mutate(class_wins1 = mapply(function(x, y, z) {
  ifelse(is.na(x), (y + z)/2, 
         ifelse(is.na(y), (x + z)/2, 
                ifelse(is.na(z), (x + y)/2, (x + y + z)/3)))}, 
  grad_sqrt, colle_sqrt, high_sqrt))

expertise6_sqrt <- expertise6_sqrt %>% mutate(media_wins1 = mapply(function(x, y, z, t, r) {
  ifelse(is.na(x), (y + z + t + r)/4, 
         ifelse(is.na(y), (x + z + t + r)/4,
                ifelse(is.na(z), (x + y + t + r)/4, 
                       ifelse(is.na(t),(x + y + z + r)/4, 
                              ifelse(is.na(r),(x + y + z + t)/4,
                                     (x + y + z + t + r)/5)))))}, 
  docu_sqrt,inarti_sqrt, radio_sqrt, numbook_sqrt, numarticle_sqrt))

```

## Center the variables

```{r warning = FALSE, message = FALSE}

expertise6_sqrt$know_cent <- scale(expertise6_sqrt$know, center = TRUE, scale = FALSE)

expertise6_sqrt$needforclo_cent <- scale(expertise6_sqrt$needforclo, center = TRUE, scale = FALSE)

expertise6_sqrt$class_wins1_cent <- scale(expertise6_sqrt$class_wins1, center = TRUE, scale = FALSE)

expertise6_sqrt$media_wins1_cent <- scale(expertise6_sqrt$media_wins1, center = TRUE, scale = FALSE)

```

## HLM Models

### Model of objective expertise, perceived expertise and need for cognition without interaction

```{r}
Model.1.1<-lmer(ih ~class_wins1_cent + media_wins1_cent + know_cent +needforclo_cent +(1|Score_Type)+(1|ID),   
              data=expertise6_sqrt)
summary(Model.1.1)
```

#Cube root variables

##Cube root of the raw variables for our new expertise variables

```{r warning = FALSE, message = FALSE}
# cube root of the variables 
expertise6_cube <- expertise6_fact%>%
  mutate(numarticle_cube=(numarticle^(1/3)),
         numbook_cube=(numbook^(1/3)),
         high_cube=(high^(1/3)),
         colle_cube=(colle^(1/3)),
         grad_cube=(grad^(1/3)),
         docu_cube=(numdocu^(1/3)),
         inarti_cube=(numinarti^(1/3)),
         radio_cube=(numradio^(1/3)))

```

```{r warning = FALSE, message = FALSE}
# Standardize the Selected variables  ----
vars_to_standardize <- c("know", "docu_cube","inarti_cube", "radio_cube","high_cube", "colle_cube",
                         "numarticle_cube", "numbook_cube", "grad_cube")



expertise6_cube<-expertise6_cube %>% 
  group_by(Score_Type) %>% 
  mutate_at(vars(vars_to_standardize), scale)

```

## Take the means of winsorized variables to create our new categories: media and class

```{r warning = FALSE, message = FALSE}

expertise6_cube <- expertise6_cube %>% mutate(class_wins1 = mapply(function(x, y, z) {
  ifelse(is.na(x), (y + z)/2, 
         ifelse(is.na(y), (x + z)/2, 
                ifelse(is.na(z), (x + y)/2, (x + y + z)/3)))}, 
  grad_cube, colle_cube, high_cube))

expertise6_cube <- expertise6_cube %>% mutate(media_wins1 = mapply(function(x, y, z, t, r) {
  ifelse(is.na(x), (y + z + t + r)/4, 
         ifelse(is.na(y), (x + z + t + r)/4,
                ifelse(is.na(z), (x + y + t + r)/4, 
                       ifelse(is.na(t),(x + y + z + r)/4, 
                              ifelse(is.na(r),(x + y + z + t)/4,
                                     (x + y + z + t + r)/5)))))}, 
  docu_cube,inarti_cube, radio_cube, numbook_cube, numarticle_cube))

```

##Histograms of square root variables

```{r warning = FALSE, message = FALSE}
hist(expertise6_sqrt$class_wins1)
```

```{r warning = FALSE, message = FALSE}
hist(expertise6_sqrt$media_wins1)
```

```{r warning = FALSE, message = FALSE}
hist(expertise6_sqrt$know)
```

```{r warning = FALSE, message = FALSE}
hist(expertise6_sqrt$ih)
```

##Shapiro-Wilk values

```{r warning = FALSE, message = FALSE}
descriptives(expertise6_sqrt, vars = vars(class_wins1, media_wins1, know, ih), n=FALSE, missing= FALSE, median=FALSE, sw = TRUE)
```

## Center the variables

```{r warning = FALSE, message = FALSE}

expertise6_cube$know_cent <- scale(expertise6_cube$know, center = TRUE, scale = FALSE)

expertise6_cube$needforclo_cent <- scale(expertise6_cube$needforclo, center = TRUE, scale = FALSE)

expertise6_cube$class_wins1_cent <- scale(expertise6_cube$class_wins1, center = TRUE, scale = FALSE)

expertise6_cube$media_wins1_cent <- scale(expertise6_cube$media_wins1, center = TRUE, scale = FALSE)

```

##Histograms of cube root variables

```{r warning = FALSE, message = FALSE}
hist(expertise6_cube$class_wins1)
```

```{r warning = FALSE, message = FALSE}
hist(expertise6_cube$media_wins1)
```

```{r warning = FALSE, message = FALSE}
hist(expertise6_cube$know)
```

```{r warning = FALSE, message = FALSE}
hist(expertise6_cube$ih)
```

##Shapiro-Wilk values

```{r warning = FALSE, message = FALSE}
descriptives(expertise6_cube, vars = vars(class_wins1, media_wins1, know, ih),n=FALSE, missing= FALSE, median=FALSE, sw = TRUE)
```

## HLM Models

### Model of objective expertise, perceived expertise and need for cognition without interaction

```{r}
Model.1.1<-lmer(ih ~class_wins1_cent + media_wins1_cent + know_cent +needforclo_cent +(1|Score_Type)+(1|ID),   
              data=expertise6_cube)
summary(Model.1.1)
```
