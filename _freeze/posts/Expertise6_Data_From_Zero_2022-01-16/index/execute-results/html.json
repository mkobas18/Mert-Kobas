{
  "hash": "ce0ffb30f23d4fe15f00a403569740eb",
  "result": {
    "markdown": "---\ntitle: \"Expertise6 Data Analysis from the very beginning\"\nauthor: \"MK\"\ndate: \"2023-01-16\"\ncategories: [example data, code, analysis]\nimage: \"newdata.png\"\n---\n\n\nThis post includes the trial analyses of an example data related to expertise.\n\nNotes: Need for closure scores haven't been calculated, the reverse items will be checked.\nNotes: For the long format, internet article, documentaries and podcast series should be added.\n\n### Import necessary packages and expertise data\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Import library ----\nlibrary(tidyverse)\nlibrary(readr)\nlibrary(purrr)\nlibrary(jmv)\nlibrary(psych)\nlibrary(DescTools)\nlibrary(stats)\nlibrary(factoextra)\n\n#Read the csv file ----\nExpertise6 <- read_csv(\"~/Desktop/Expertise6_5.8.14_December 23, 2022_10.51 2.csv\")\n```\n:::\n\n\nCreates a new dataframe called expertise6_clean, which is a copy of the original dataframe called expertise6 and removes the second row of the dataframe and create a variable called column_names and assign it the names of the columns in the dataframe and change the column names\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#removes the second row of the dataframe\nexpertise6_clean<-Expertise6%>% \n  slice(-2) \n\n\n#selects all columns except the ones listed \nexpertise6_clean <- expertise6_clean %>%\n  select(-StartDate, -EndDate, -Status, -Progress,-ResponseId,-RecordedDate,-RecipientLastName, -RecipientFirstName,-RecipientEmail, -ExternalReference, -LocationLatitude,-LocationLongitude, -DistributionChannel, -UserLanguage)\n\n#create a variable called column_names and assign it the names of the columns in the dataframe\ncolumn_names <- names(expertise6_clean)\n\ncolumn_names\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  [1] \"IPAddress\"             \"Duration (in seconds)\" \"Finished\"             \n  [4] \"Q39\"                   \"Q40\"                   \"Q41\"                  \n  [7] \"Q42\"                   \"Q43\"                   \"Q44\"                  \n [10] \"Q45\"                   \"Q46\"                   \"Q47\"                  \n [13] \"Q48\"                   \"Q49\"                   \"Q50\"                  \n [16] \"Q51\"                   \"Q52\"                   \"Q53\"                  \n [19] \"Q54\"                   \"Q147_1\"                \"Q149_1\"               \n [22] \"Q151_1\"                \"Q153_1\"                \"Q155_1\"               \n [25] \"Q157_1\"                \"Q159_1\"                \"Q161_1\"               \n [28] \"Q69\"                   \"Q3_1\"                  \"Q3_2\"                 \n [31] \"Q3_3\"                  \"Q70\"                   \"Q4\"                   \n [34] \"Q71\"                   \"Q5\"                    \"Q204\"                 \n [37] \"Q209...51\"             \"Q206\"                  \"Q210\"                 \n [40] \"Q208\"                  \"Q211...55\"             \"Q73\"                  \n [43] \"Q74_1\"                 \"Q74_2\"                 \"Q74_3\"                \n [46] \"Q75\"                   \"Q76...61\"              \"Q77\"                  \n [49] \"Q78...63\"              \"Q214...64\"             \"Q219...65\"            \n [52] \"Q216\"                  \"Q214...67\"             \"Q218\"                 \n [55] \"Q215...69\"             \"Q80...70\"              \"Q81_1\"                \n [58] \"Q81_2\"                 \"Q81_3\"                 \"Q82\"                  \n [61] \"Q83\"                   \"Q84\"                   \"Q85\"                  \n [64] \"Q217...78\"             \"Q222\"                  \"Q219...80\"            \n [67] \"Q223...81\"             \"Q221...82\"             \"Q224\"                 \n [70] \"Q87\"                   \"Q88_1\"                 \"Q88_2\"                \n [73] \"Q88_3\"                 \"Q89\"                   \"Q90\"                  \n [76] \"Q91\"                   \"Q92\"                   \"Q226\"                 \n [79] \"Q231...93\"             \"Q228\"                  \"Q232\"                 \n [82] \"Q230\"                  \"Q233...97\"             \"Q94\"                  \n [85] \"Q95_1\"                 \"Q95_2\"                 \"Q95_3\"                \n [88] \"Q96\"                   \"Q97\"                   \"Q98\"                  \n [91] \"Q99\"                   \"Q245...106\"            \"Q246...107\"           \n [94] \"Q247...108\"            \"Q248...109\"            \"Q249...110\"           \n [97] \"Q250...111\"            \"Q101\"                  \"Q102_1\"               \n[100] \"Q102_2\"                \"Q102_3\"                \"Q103\"                 \n[103] \"Q104\"                  \"Q105\"                  \"Q106\"                 \n[106] \"Q235...120\"            \"Q240\"                  \"Q237...122\"           \n[109] \"Q241...123\"            \"Q239...124\"            \"Q242\"                 \n[112] \"Q108\"                  \"Q109_1\"                \"Q109_2\"               \n[115] \"Q109_3\"                \"Q110\"                  \"Q111\"                 \n[118] \"Q112\"                  \"Q113\"                  \"Q244\"                 \n[121] \"Q249...135\"            \"Q246...136\"            \"Q250...137\"           \n[124] \"Q248...138\"            \"Q251...139\"            \"Q115\"                 \n[127] \"Q116_1\"                \"Q116_2\"                \"Q116_3\"               \n[130] \"Q117\"                  \"Q118\"                  \"Q119\"                 \n[133] \"Q120\"                  \"Q253\"                  \"Q258\"                 \n[136] \"Q255\"                  \"Q259\"                  \"Q257\"                 \n[139] \"Q251...153\"            \"Q167\"                  \"Q169\"                 \n[142] \"Q171\"                  \"Q173\"                  \"Q175\"                 \n[145] \"Q177\"                  \"Q179\"                  \"Q181\"                 \n[148] \"Q183\"                  \"Q185\"                  \"Q187\"                 \n[151] \"Q189\"                  \"Q191\"                  \"Q193\"                 \n[154] \"Q195\"                  \"Q197\"                  \"Q199\"                 \n[157] \"Q201\"                  \"Q203\"                  \"Q205\"                 \n[160] \"Q207\"                  \"Q209...175\"            \"Q211...176\"           \n[163] \"Q213\"                  \"Q215...178\"            \"Q217...179\"           \n[166] \"Q219...180\"            \"Q221...181\"            \"Q223...182\"           \n[169] \"Q225\"                  \"Q227\"                  \"Q229\"                 \n[172] \"Q231...186\"            \"Q233...187\"            \"Q235...188\"           \n[175] \"Q237...189\"            \"Q239...190\"            \"Q241...191\"           \n[178] \"Q243\"                  \"Q245...193\"            \"Q247...194\"           \n[181] \"Q249...195\"            \"Q58\"                   \"Q60_1\"                \n[184] \"Q62\"                   \"Q64_1\"                 \"Q64_2\"                \n[187] \"Q64_3\"                 \"Q64_4\"                 \"Q66\"                  \n[190] \"Q68\"                   \"Q72\"                   \"Q74\"                  \n[193] \"Q76...207\"             \"Q78...208\"             \"Q80...209\"            \n[196] \"SurveyOrder\"          \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n##Change the column names ----\ncolnames(expertise6_clean) <- c('ip','duration', 'finished', 'stih_food','r_ih_food',\n                        'stih_sports','r_ih_sports','stih_school','r_ih_school',\n                        'stih_architect','r_ih_architect','stih_product','r_ih_product',                                'stih_langu','r_ih_langu','stih_network','r_ih_network',\n                        'stih_anthro','r_ih_anthro',\n                        'know_food','know_sports','know_school','know_architect',\n                        'know_product','know_langu','know_network','know_anthro',\n                        'course_food','high_food', 'colle_food', 'grad_food',\n                        'book_food','numbook_food','article_food','numarticle_food',\n                        'in_arti_food','numinarti_food', 'docu_food', 'numdocu_food',\n                        'radio_food','numradio_food',\n                        'course_sports','high_sports', 'colle_sports', 'grad_sports',\n                        'book_sports','numbook_sports','article_sports','numarticle_sports',\n                        'in_arti_sports','numinarti_sports', 'docu_sports', 'numdocu_sports',\n                        'radio_sports','numradio_sports',\n                        'course_school','high_school', 'colle_school', 'grad_school',\n                        'book_school','numbook_school','article_school','numarticle_school',\n                        'in_arti_school','numinarti_school', 'docu_school', 'numdocu_school',\n                        'radio_school','numradio_school',\n                        'course_architect','high_architect', 'colle_architect','grad_architect',\n                        'book_architect','numbook_architect','article_architect',\n                        'numarticle_architect',\n                        'in_arti_architect','numinarti_architect', \n                        'docu_architect', 'numdocu_architect',\n                        'radio_architect','numradio_architect',\n                        'course_product','high_product', 'colle_product', 'grad_product',\n                        'book_product','numbook_product','article_product',\n                        'numarticle_product',\n                        'in_arti_product','numinarti_product', 'docu_product', 'numdocu_product',\n                        'radio_product','numradio_product',\n                        'course_langu','high_langu', 'colle_langu', 'grad_langu',\n                        'book_langu','numbook_langu','article_langu','numarticle_langu',\n                        'in_arti_langu','numinarti_langu', 'docu_langu', 'numdocu_langu',\n                        'radio_langu','numradio_langu',\n                        'course_network','high_network', 'colle_network', 'grad_network',\n                        'book_network','numbook_network','article_network','numarticle_network',\n                        'in_arti_network','numinarti_network', 'docu_network', 'numdocu_network',\n                        'radio_network','numradio_network',\n                        'course_anthro','high_anthro', 'colle_anthro', 'grad_anthro',\n                        'book_anthro','numbook_anthro','article_anthro','numarticle_anthro',\n                        'in_arti_anthro','numinarti_anthro', 'docu_anthro', 'numdocu_anthro',\n                        'radio_anthro','numradio_anthro',\n                        'needforclo1','needforclo2','needforclo3','needforclo4','needforclo5',\n                        'needforclo6','needforclo7','needforclo8','needforclo9','needforclo10',\n                        'needforclo11','needforclo12','needforclo13','needforclo14',\n                        'needforclo15','needforclo16','needforclo17','needforclo18',\n                        'needforclo19','needforclo20','needforclo21','needforclo22',\n                        'needforclo23','needforclo24','needforclo25','needforclo26',\n                        'needforclo27','needforclo28','needforclo29','needforclo30',\n                        'needforclo31','needforclo32','needforclo33','needforclo34',\n                        'needforclo35','needforclo36','needforclo37','needforclo38',\n                        'needforclo39','needforclo40','needforclo41','needforclo42',\n                        'sex','birthdate','education','income','religion',\n                        'identity','age','political_atti','english_level','proceure_confu',\n                        'whatwestudied','moretothisstudy','additional_thoughts','attention', \n                        'surveyorder')\n```\n:::\n\n\n\n### Questionnaire Items\n\nThe code below shows the survey items:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#selects all columns except the ones specified\nrow_values <- expertise6_clean %>%\n  select(-duration,-finished, -ip, -surveyorder)%>%\n  #selects only the first row\n  filter(row_number() == 1)\n\n#Items in the questionnaire ----\n\n#unlist the row_values\nrow_values <- unlist(row_values)\n\nmy_list <- map(row_values, ~paste0(.))\n\nlibrary(stringr)\nmy_list <- str_replace(my_list, \"(?<! )\\\\n(?! )\", \"\")\nmy_list <- str_replace(my_list, \"[^\\\\s]*\\\\\\\\n[^\\\\s]*\", \"\")\nlist_string <- paste0(\"* \", paste(my_list, collapse = \"\\n* \"))\n\n##Show the survey items ----\ncat(list_string)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n* There are good reasons why drive-thrus are typically associated with fast-food restaurants. There are things about drive-thrus that make them less suited for fancy or upscale restaurants.\n* Even though we don’t typically see drive-thrus at fancy restaurants, there is no real reason why fancy restaurants don’t have drive-thrus. This practice could have easily been different.\n* It seems natural that we sing the national anthem before sporting events, rather than after. The national anthem just fits better at the beginning of a sports game.\n* When you really think about, singing the national anthem before sporting events is just a convention. If history had unfolded differently, it’s possible that we would be singing it after the events, or maybe even not at all.\n* It seems right that students receive letter grades in school (A, B, C, …) to measure their performance. Another evaluative process would likely not work as well.\n* It’s likely that evaluating students’ performance with letter grades (A, B, C, …) is not the best practice. Another evaluative process may be more effective than letter grading.\n* It probably works best for homes to be painted with neutral or muted colors (e.g., white, gray). Bright or neon-colored homes (e.g., red, purple) would not be practical.\n* Although homes are usually painted with neutral or muted colors (e.g., white, gray), this could have been done differently.  It’s quite possible that homes could have been painted with brighter colors (e.g., red, purple).\n* It seems ideal that forks usually have three or four prongs, rather than more prongs (for example, six or seven). Three or four prongs on forks is probably the best design.\n* There’s no good reason why forks only have three or four prongs. Forks with more prongs (for example, six or seven) would work just as well; in principle, forks could have been designed that way too.\n* It seems natural that the letter “s” at the end of a word is used to indicate plurality (as in \"cats\" or \"trees\"). Another way of signaling plurality would not work as well.\n* Had historical events unfolded differently, it’s possible that the English language would indicate plurality in a different way than using the letter “s” (as in \"cats\" or \"trees\"). There’s nothing inherently special about the letter “s” for this purpose.\n* There are good reasons why we use digits, rather than letters, to call people on the phone.  Using digits seems like the optimal way to make phone calls.\n* The only reason why we use digits, rather than letters, to call people is historical happenstance.  Phones calls could have just as easily been made with a variety of symbols other than digits (for example, letters).\n* It seems natural that people wear black to funerals. There is something about the color black that indicates mourning.\n* When you think about it, colors other than black could have just as easily become associated with funerals (for example, white). Had history taken a different turn, another color may now signal mourning and sadness.\n* How much do you know about the food industry and restaurant business? - Please use the slider to select your answer choice.\n* How much do you know about sports and sports management? - Please use the slider to select your answer choice.\n* How much do you know about school and education systems? - Please use the slider to select your answer choice.\n* How much do you know about architecture and home design? - Please use the slider to select your answer choice.\n* How much do you know about product design and usability? - Please use the slider to select your answer choice.\n* How much do you know about language and linguistics? - Please use the slider to select your answer choice.\n* How much do you know about telecommunication and network systems? - Please use the slider to select your answer choice.\n* How much do you know about anthropology and funeral rites? - Please use the slider to select your answer choice.\n* Have you ever taken a class that discussed the food industry and restaurant business?\n* If you answered \"yes\" above, please approximate the number of classes of this sort you took in: - High School\n* If you answered \"yes\" above, please approximate the number of classes of this sort you took in: - College\n* If you answered \"yes\" above, please approximate the number of classes of this sort you took in: - Graduate School\n* Have you ever read any books on the food industry and restaurant business?\n* If you answered \"yes\" above, please approximate the number of books you have read on this topic:\n* Have you ever read any magazine, newspaper, or academic articles on the food industry and restaurant business?\n* If you answered \"yes\" above, please approximate the number of articles you have read on this topic:\n* Have you ever read any articles while browsing the internet  (e.g., on Reddit, Pinterest, Buzzfeed) on the food industry and restaurant business?\n* If you answered \"yes\" above, please approximate the number of articles on the internet you have read on this topic:\n* Have you ever seen any documentaries (e,g., on the Discovery channel) on the food industry and restaurant business?\n* If you answered \"yes\" above, please approximate the number of documentaries you have seen on this topic:\n* Have you ever heard any radio shows or podcasts (e.g., NPR) on the food industry and restaurant business?\n* If you answered \"yes\" above, please approximate the number of radio shows or podcasts you have heard on this topic:\n* Have you ever taken a class that discussed sports and sports management?\n* If you answered \"yes\" above, please approximate the number of classes of this sort you took in: - High School\n* If you answered \"yes\" above, please approximate the number of classes of this sort you took in: - College\n* If you answered \"yes\" above, please approximate the number of classes of this sort you took in: - Graduate School\n* Have you ever read any books on sports and sports management?\n* If you answered \"yes\" above, please approximate the number of books you have read on this topic:\n* Have you ever read any magazine, newspaper, or academic articles on sports and sports management?\n* If you answered \"yes\" above, please approximate the number of articles you have read on this topic:\n* Have you ever read any articles while browsing the internet  (e.g., on Reddit, Pinterest, Buzzfeed) on sports and sports management?\n* If you answered \"yes\" above, please approximate the number of articles on the internet you have read on this topic:\n* Have you ever watched any documentaries (e,g., on the Discovery channel) on sports and sports management?\n* If you answered \"yes\" above, please approximate the number of documentaries you have seen on this topic:\n* Have you ever heard any radio shows or podcasts (e.g., NPR) on sports and sports management?\n* If you answered \"yes\" above, please approximate the number of radio shows or podcasts you have heard on this topic:\n* Have you ever taken a class that discussed school and education systems?\n* If you answered \"yes\" above, please approximate the number of classes of this sort you took in: - High School\n* If you answered \"yes\" above, please approximate the number of classes of this sort you took in: - College\n* If you answered \"yes\" above, please approximate the number of classes of this sort you took in: - Graduate School\n* Have you ever read any books on school and education systems?\n* If you answered \"yes\" above, please approximate the number of books you have read on this topic:\n* Have you ever read any magazine, newspaper, or academic articles on school and education systems?\n* If you answered \"yes\" above, please approximate the number of articles you have read on this topic:\n* Have you ever read any articles while browsing the internet  (e.g., on Reddit, Pinterest, Buzzfeed) on school and education systems?\n* If you answered \"yes\" above, please approximate the number of articles on the internet you have read on this topic:\n* Have you ever watched any documentaries (e,g., on the Discovery channel) on school and education systems?\n* If you answered \"yes\" above, please approximate the number of documentaries you have seen on this topic:\n* Have you ever heard any radio shows or podcasts (e.g., NPR) have you heard on school and education systems?\n* If you answered \"yes\" above, please approximate the number of radio shows or podcasts you have seen on this topic:\n* Have you ever taken a class that discussed architecture and home design?\n* If you answered \"yes\" above, please approximate the number of classes of this sort you took in: - High School\n* If you answered \"yes\" above, please approximate the number of classes of this sort you took in: - College\n* If you answered \"yes\" above, please approximate the number of classes of this sort you took in: - Graduate School\n* Have you ever read any books on architecture and home design?\n* If you answered \"yes\" above, please approximate the number of books you have read on this topic:\n* Have you ever read any magazine, newspaper, or academic articles on architecture and home design?\n* If you answered \"yes\" above, please approximate the number of articles you have read on this topic:\n* Have you ever read any articles while browsing the internet  (e.g., on Reddit, Pinterest, Buzzfeed) on architecture and home design?\n* If you answered \"yes\" above, please approximate the number of articles on the internet you have read on this topic:\n* Have you ever seen any documentaries (e,g., on the Discovery channel) on architecture and home design?\n* If you answered \"yes\" above, please approximate the number of documentaries you have seen on this topic:\n* Have you ever heard any radio shows or podcasts (e.g., NPR) on architecture and home design?\n* If you answered \"yes\" above, please approximate the number of radio shows or podcasts you have heard on this topic:\n* Have you ever taken a class that discussed product design and usability?\n* If you answered \"yes\" above, please approximate the number of classes of this sort you took in: - High School\n* If you answered \"yes\" above, please approximate the number of classes of this sort you took in: - College\n* If you answered \"yes\" above, please approximate the number of classes of this sort you took in: - Graduate School\n* Have you ever read any books on product design and usability?\n* If you answered \"yes\" above, please approximate the number of books you have read on this topic:\n* Have you ever read any magazine, newspaper, or academic articles on product design and usabilityt?\n* If you answered \"yes\" above, please approximate the number of articles you have read on this topic:\n* Have you ever read any articles while browsing the internet  (e.g., on Reddit, Pinterest, Buzzfeed) on product design and usability?\n* If you answered \"yes\" above, please approximate the number of articles on the internet you have read on this topic:\n* Have you ever seen any documentaries (e,g., on the Discovery channel) on product design and usability?\n* If you answered \"yes\" above, please approximate the number of documentaries you have seen on this topic:\n* Have you ever heard any radio shows or podcasts (e.g., on Reddit, Pinterest, Buzzfeed) on product design and usability?\n* If you answered \"yes\" above, please approximate the number of radio shows or podcasts you have heard on this topic:\n* Have you ever taken a class that discussed language and linguistics?\n* If you answered \"yes\" above, please approximate the number of classes of this sort you took in: - High School\n* If you answered \"yes\" above, please approximate the number of classes of this sort you took in: - College\n* If you answered \"yes\" above, please approximate the number of classes of this sort you took in: - Graduate School\n* Have you ever read any books on language and linguistics?\n* If you answered \"yes\" above, please approximate the number of books you have read on this topic:\n* Have you ever read any magazine, newspaper, or academic articles on language and linguistics?\n* If you answered \"yes\" above, please approximate the number of articles you have read on this topic:\n* Have you ever read any articles while browsing the internet  (e.g., on Reddit, Pinterest, Buzzfeed) on language and linguistics?\n* If you answered \"yes\" above, please approximate the number of articles on the internet you have read on this topic:\n* Have you ever seen any documentaries (e,g., on the Discovery channel) on language and linguistics?\n* If you answered \"yes\" above, please approximate the number of documentaries you have seen on this topic:\n* Have you ever heard any radio shows or podcasts (e.g., NPR) on language and linguistics?\n* If you answered \"yes\" above, please approximate the number of radio shows or podcasts you have heard on this topic:\n* Have you ever taken a class that discussed telecommunication and network systems?\n* If you answered \"yes\" above, please approximate the number of classes of this sort you took in: - High School\n* If you answered \"yes\" above, please approximate the number of classes of this sort you took in: - College\n* If you answered \"yes\" above, please approximate the number of classes of this sort you took in: - Graduate School\n* Have you ever read any books on telecommunication and network systems?\n* If you answered \"yes\" above, please approximate the number of books you have read on this topic:\n* Have you ever read any magazine, newspaper, or academic articles on telecommunication and network systems?\n* If you answered \"yes\" above, please approximate the number of articles you have read on this topic:\n* Have you ever read any articles while browsing the internet  (e.g., on Reddit, Pinterest, Buzzfeed) on telecommunication and network systems?\n* If you answered \"yes\" above, please approximate the number of articles on the internet you have read on this topic:\n* Have you ever seen any documentaries (e,g., on the Discovery channel) on telecommunication and network systems?\n* If you answered \"yes\" above, please approximate the number of documentaries you have seen on this topic:\n* Have you ever heard any radio shows or podcasts (e.g., NPR) on telecommunication and network systems?\n* If you answered \"yes\" above, please approximate the number of radio shows or podcasts you have heard on this topic:\n* Have you ever taken a class that discussed anthropology and funeral rites?\n* If you answered \"yes\" above, please approximate the number of classes of this sort you took in: - High School\n* If you answered \"yes\" above, please approximate the number of classes of this sort you took in: - College\n* If you answered \"yes\" above, please approximate the number of classes of this sort you took in: - Graduate School\n* Have you ever read any books on anthropology and funeral rites?\n* If you answered \"yes\" above, please approximate the number of books you have read on this topic:\n* Have you ever read any magazine, newspaper, or academic articles on anthropology and funeral rites?\n* If you answered \"yes\" above, please approximate the number of articles you have read on this topic:\n* Have you ever read any articles while browsing the internet  (e.g., on Reddit, Pinterest, Buzzfeed) on anthropology and funeral rites?\n* If you answered \"yes\" above, please approximate the number of articles on the internet you have read on this topic:\n* Have you ever seen any documentaries (e,g., on the Discovery channel) on anthropology and funeral rites?\n* If you answered \"yes\" above, please approximate the number of documentaries you have seen on this topic:\n* Have you ever heard any radio shows or podcasts (e.g., NPR) on anthropology and funeral rites?\n* If you answered \"yes\" above, please approximate the number of radio shows or podcasts you have heard on this topic:\n* I enjoy having a clear and structured mode of life.\n* I like to have a place for everything and everything in its place.\n* I find that establishing a consistent routine enables me to enjoy life more\n* I find that a well ordered life with regular hours suits my temperament.\n* My personal space is usually messy and disorganized.\n* I believe that orderliness and organization are among the most important characteristics of a good student.\n* I think that having clear rules and order at work is essential for success.\n* I think that I would learn best in a class that lacks clearly stated objectives and requirements.\n* I dislike the routine aspects of my work (studies).\n* I hate to change my plans at the last minute.\n* I dislike it when a person's statement could mean many different things.\n* I feel uncomfortable when someone's meaning or intention is unclear to me.\n* I feel uncomfortable when I don't understand the reason why an event occurred in my life.\n* It's annoying to listen to someone who cannot seem to make up his or her mind.\n* When I am confused about an important issue, I feel very upset.\n* I like to know what people are thinking all the time.\n* In most social conflicts, I can easily see which side is right and which is wrong.\n* I'd rather know bad news than stay in a state of uncertainty.\n* I don't like situations that are uncertain.\n* When thinking about a problem, I consider as many different opinions on the issue as possible.\n* When considering most conflict situations, I can usually see how both sides could be right.\n* I always see many possible solutions to problems I face.\n* I do not usually consult many different opinions before forming own view.\n* Even after I've made up my mind about something, I am always eager to consider a different opinion.\n* I prefer interacting with people whose opinions are very different from my own.\n* I dislike questions which could be answered in many different ways.\n* I feel irritated when one person disagrees with what everyone else in a group believes.\n* I like to have friends who are unpredictable.\n* When dining out, I like to go to places where I have been before so that I know what to expect.\n* I don't like to go into a situation without knowing what I can expect from it\n* I think it is fun to change my plans at the last moment.\n* I enjoy the uncertainty of going into a new situation without knowing what might happen.\n* I don't like to be with people who are capable of unexpected actions.\n* I prefer to socialize with familiar friends because I know what to expect from them.\n* I dislike unpredictable situations.\n* When I go shopping, I have difficulty deciding exactly what it is that I want.\n* When faced with a problem I usually see the one best solution very quickly.\n* I tend to put off making important decisions until the last possible moment.\n* I usually make important decisions quickly and confidently.\n* I would describe myself as indecisive.\n* I tend to struggle with most decisions.\n* When trying to solve a problem I often see so many possible options that it's confusing.\n* Are you male or female?\n* Q60 - What is your date of birth? (mm/dd/yyyy)\n* What is the highest level of education you have completed?\n* Q64 - What is your yearly household income?\n* Q64 - What is your religious affiliation?\n* Q64 - What is your racial or ethnic identity?\n* Q64 - What is your age in years?\n* How would you describe your political attitudes? Please select one of the points on the scale below.\n* Please rate your overall ability in the English language:\n* 1. Did you find any aspect of the procedure odd or confusing?\n* 2. What did you think we were studying?\n* 3. Do you think that there may have been more to this study than meets the eye? If so, what do you think this might have been?\n* 4. Do you have any additional thoughts or comments about the study?\n* Thank you for completing this survey! We just have one last question for you. You will not be penalized for your answer to this question. Since you completed the whole survey, you will receive payment no matter what answer you give here.\n\t \n\n\tIt's very important to the quality and scientific aims of our study that participants pay attention (i.e., read the survey carefully, consider the response options, and avoid distractions).\n\n\t\n\n\tWere you paying attention while completing this survey?\n```\n:::\n:::\n\n\n### Exclusion Criterias\n\nData preparation for further analyses\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Attention check and deletion of cases that didn't attend or finish the study ----\nexpertise6_new<-expertise6_clean%>%\n  filter(attention==1&finished==1)\n\n\n##Exclude the participants that joined outside of US ----\n\n#view(expertise6_new)\nexpertise6_new<-expertise6_new%>%\n  filter(ip!=\"66.42.251.231\")\n\nexpertise6_new <- expertise6_new %>%\n  filter(!(ip %in% c(\"74.219.142.226\", \"24.12.92.17\", \"184.88.52.194\", \n                     \"97.103.220.145\", \"76.250.238.38\")))\n\n##selecting the columns that we want to keep ----\nexpertise6_new<-expertise6_new%>%\n  select(-finished,-birthdate,-proceure_confu,-whatwestudied,-moretothisstudy,-additional_thoughts,-attention, -surveyorder)\n\n#adds a column to the dataframe, with the name \"id\"\nexpertise6_new<-cbind(ID = 1:nrow(expertise6_new), expertise6_new)\n\n# Numeric variables ----\n# Change the data type of the variables to numeric \nexpertise6_new <- expertise6_new %>%\n  mutate_at(vars(stih_food, r_ih_food, stih_sports, r_ih_sports, stih_school, r_ih_school, stih_architect, r_ih_architect, \n                 stih_product, r_ih_product, stih_langu, r_ih_langu, stih_network, r_ih_network, stih_anthro, r_ih_anthro), as.numeric)\n```\n:::\n\n\n## Correlation for ih scores\n\nCheck the correlations between inherence (the variables starting with st) and reverse inherence (the variables starting with r) scores to check whether it's appropriate for averaging\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Correlations between ih scores ----\n\n# Create a list of variable names\nvariables <- c(\"stih_food\", \"r_ih_food\", \"stih_sports\", \"r_ih_sports\", \"stih_school\", \"r_ih_school\", \"stih_architect\", \"r_ih_architect\", \"stih_product\", \"r_ih_product\", \"stih_langu\", \"r_ih_langu\", \"stih_network\", \"r_ih_network\", \"stih_anthro\", \"r_ih_anthro\")\n\n# Initialize an empty data frame to store the correlation coefficients\ncorrelations <- data.frame(variable1 = character(), variable2 = character(), correlation = numeric(), p.value = numeric(), conf.int = character())\n\n# Iterate over the pairs of variables\nfor (i in seq(1, length(variables), 2)) {\n  j <- i + 1\n  \n  # Calculate the Pearson correlation coefficient and test the statistical significance\n  correlation_test <- cor.test(expertise6_new[, variables[i]], expertise6_new[, variables[j]], method = \"pearson\")\n  \n  # Add the correlation coefficient, p-value, and confidence interval to the data frame\n  correlations <- rbind(correlations, data.frame(variable1 = variables[i], variable2 = variables[j], correlation = correlation_test$estimate, p.value = correlation_test$p.value, conf.int = paste(correlation_test$conf.int[1], correlation_test$conf.int[2], sep = \" - \")))}\n\n## View the correlation coefficients and statistical measures ----\ncorrelations\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          variable1      variable2 correlation      p.value\ncor       stih_food      r_ih_food  -0.4463858 8.615861e-11\ncor1    stih_sports    r_ih_sports  -0.5753914 2.560996e-18\ncor2    stih_school    r_ih_school  -0.7267533 8.094747e-33\ncor3 stih_architect r_ih_architect  -0.6411731 1.275191e-23\ncor4   stih_product   r_ih_product  -0.6038601 1.834983e-20\ncor5     stih_langu     r_ih_langu  -0.5635496 1.740797e-17\ncor6   stih_network   r_ih_network  -0.5898848 2.202312e-19\ncor7    stih_anthro    r_ih_anthro  -0.5442449 3.376865e-16\n                                    conf.int\ncor  -0.553035668300546 - -0.325343101426943\ncor1 -0.662979980870432 - -0.472263234194049\ncor2  -0.787333698376605 - -0.65227324221234\ncor3 -0.717624383417027 - -0.549452592494561\ncor4 -0.686743816747194 - -0.505475832894281\ncor5 -0.653042937790108 - -0.458533845459347\ncor6  -0.675100225685499 - -0.48913522712539\ncor7 -0.636777009250974 - -0.436258848944745\n```\n:::\n:::\n\n\n## IH scores calculation\n\nIt seems that each pairs have negative significant correlation, so we can take the average scores to calculate inherence scores\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Average of ih scores  ----\n#It seems that each pairs have negative significant correlation, so we can take the average scores to measure inherence scores\nexpertise6_new <- expertise6_new %>%\n  mutate(ih_food = (stih_food + (10 - r_ih_food))/2,\n         ih_sports = (stih_sports + (10 - r_ih_sports)) / 2,\n         ih_school = (stih_school + (10 - r_ih_school)) / 2,\n         ih_architect = (stih_architect + (10 - r_ih_architect)) / 2,\n         ih_product = (stih_product + (10 - r_ih_product)) / 2,\n         ih_langu = (stih_langu + (10 - r_ih_langu)) / 2,\n         ih_network = (stih_network + (10-r_ih_network)) / 2,\n         ih_anthro = (stih_anthro + (10-r_ih_anthro)) / 2 )\n```\n:::\n\n\n## Need for Cognition scores calculation\n\nCalculate \"Need for cognition\" scale scores\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Need for cognition scale scores  ----\n\n# change the data type of the variables to numeric\nexpertise6_new <- expertise6_new %>%\n  mutate_at(vars( 'needforclo1','needforclo2','needforclo3','needforclo4','needforclo5',\n                        'needforclo6','needforclo7','needforclo8','needforclo9','needforclo10',\n                        'needforclo11','needforclo12','needforclo13','needforclo14',\n                        'needforclo15','needforclo16','needforclo17','needforclo18',\n                        'needforclo19','needforclo20','needforclo21','needforclo22',\n                        'needforclo23','needforclo24','needforclo25','needforclo26',\n                        'needforclo27','needforclo28','needforclo29','needforclo30',\n                        'needforclo31','needforclo32','needforclo33','needforclo34',\n                        'needforclo35','needforclo36','needforclo37','needforclo38',\n                        'needforclo39','needforclo40','needforclo41','needforclo42'), as.numeric)\n\n## Calculate needforcog scores  ----\n#add a new variable called needforcog, which is the sum of all the need for cognition items, the items are weighted according to the scoring key\nexpertise6_new <- expertise6_new %>%\n  group_by(ID)%>%\n  mutate(needforcog=(needforclo1+needforclo2+needforclo3+needforclo4+(10-needforclo5)+\n                        needforclo6+needforclo7+(10-needforclo8)+(10-needforclo9)+needforclo10+\n                        needforclo11+needforclo12+needforclo13+needforclo14+\n                        needforclo15+needforclo16+needforclo17+needforclo18+\n                        needforclo19+needforclo20+needforclo21+needforclo22+\n                        needforclo23+needforclo24+needforclo25+needforclo26+\n                        needforclo27+needforclo28+needforclo29+needforclo30+\n                        needforclo31+needforclo32+needforclo33+needforclo34+\n                        needforclo35+needforclo36+needforclo37+needforclo38+\n                        needforclo39+needforclo40+needforclo41+needforclo42)/42)\n```\n:::\n\n\n## Data preparation\n\nPrepare the expertise scores and other scores ready for analyses\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Replace expertise variables' NA values in the expertise columns with 0  ----\nvariables <- c('know_food','know_sports','know_school','know_architect',\n                        'know_product','know_langu','know_network','know_anthro',\n                        'high_food', 'colle_food', 'grad_food',\n                        'numbook_food','numarticle_food',\n                        'numinarti_food', 'numdocu_food',\n                        'numradio_food',\n                        'high_sports', 'colle_sports', 'grad_sports',\n                        'numbook_sports','numarticle_sports',\n                        'numinarti_sports', 'numdocu_sports',\n                        'numradio_sports',\n                        'high_school', 'colle_school', 'grad_school',\n                        'numbook_school','numarticle_school',\n                        'numinarti_school','numdocu_school',\n                        'numradio_school',\n                        'high_architect', 'colle_architect','grad_architect',\n                        'numbook_architect',\n                        'numarticle_architect',\n                        'numinarti_architect', \n                        'numdocu_architect',\n                        'numradio_architect',\n                        'high_product', 'colle_product', 'grad_product',\n                        'numbook_product',\n                        'numarticle_product',\n                       'numinarti_product','numdocu_product',\n                        'numradio_product',\n                        'high_langu', 'colle_langu', 'grad_langu',\n                        'numbook_langu','numarticle_langu',\n                        'numinarti_langu', 'numdocu_langu',\n                        'numradio_langu',\n                        'high_network', 'colle_network', 'grad_network',\n                        'numbook_network','numarticle_network',\n                        'numinarti_network', 'numdocu_network',\n                        'numradio_network',\n                        'high_anthro', 'colle_anthro','grad_anthro',\n                        'numbook_anthro','numarticle_anthro',\n                        'numinarti_anthro', 'numdocu_anthro',\n                        'numradio_anthro')\n\nexpertise6_new[variables] <- lapply(expertise6_new[variables], \n                                    function(x) ifelse(is.na(x), 0, ifelse(x=='no',0,x)))\n\n# Missing values in the dataframe  ----\napply(is.na(expertise6_new), 2, sum)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  ID                   ip             duration \n                   0                    0                    0 \n           stih_food            r_ih_food          stih_sports \n                   0                    0                    0 \n         r_ih_sports          stih_school          r_ih_school \n                   0                    0                    0 \n      stih_architect       r_ih_architect         stih_product \n                   0                    0                    0 \n        r_ih_product           stih_langu           r_ih_langu \n                   0                    0                    0 \n        stih_network         r_ih_network          stih_anthro \n                   0                    0                    0 \n         r_ih_anthro            know_food          know_sports \n                   0                    0                    0 \n         know_school       know_architect         know_product \n                   0                    0                    0 \n          know_langu         know_network          know_anthro \n                   0                    0                    0 \n         course_food            high_food           colle_food \n                   1                    0                    0 \n           grad_food            book_food         numbook_food \n                   0                    0                    0 \n        article_food      numarticle_food         in_arti_food \n                   0                    0                    0 \n      numinarti_food            docu_food         numdocu_food \n                   0                    0                    0 \n          radio_food        numradio_food        course_sports \n                   0                    0                    0 \n         high_sports         colle_sports          grad_sports \n                   0                    0                    0 \n         book_sports       numbook_sports       article_sports \n                   1                    0                    0 \n   numarticle_sports       in_arti_sports     numinarti_sports \n                   0                    0                    0 \n         docu_sports       numdocu_sports         radio_sports \n                   0                    0                    0 \n     numradio_sports        course_school          high_school \n                   0                    0                    0 \n        colle_school          grad_school          book_school \n                   0                    0                    0 \n      numbook_school       article_school    numarticle_school \n                   0                    0                    0 \n      in_arti_school     numinarti_school          docu_school \n                   0                    0                    0 \n      numdocu_school         radio_school      numradio_school \n                   0                    0                    0 \n    course_architect       high_architect      colle_architect \n                   1                    0                    0 \n      grad_architect       book_architect    numbook_architect \n                   0                    0                    0 \n   article_architect numarticle_architect    in_arti_architect \n                   0                    0                    0 \n numinarti_architect       docu_architect    numdocu_architect \n                   0                    0                    0 \n     radio_architect   numradio_architect       course_product \n                   0                    0                    0 \n        high_product        colle_product         grad_product \n                   0                    0                    0 \n        book_product      numbook_product      article_product \n                   0                    0                    1 \n  numarticle_product      in_arti_product    numinarti_product \n                   0                    0                    0 \n        docu_product      numdocu_product        radio_product \n                   2                    0                    1 \n    numradio_product         course_langu           high_langu \n                   0                    0                    0 \n         colle_langu           grad_langu           book_langu \n                   0                    0                    1 \n       numbook_langu        article_langu     numarticle_langu \n                   0                    1                    0 \n       in_arti_langu      numinarti_langu           docu_langu \n                   0                    0                    1 \n       numdocu_langu          radio_langu       numradio_langu \n                   0                    0                    0 \n      course_network         high_network        colle_network \n                   1                    0                    0 \n        grad_network         book_network      numbook_network \n                   0                    0                    0 \n     article_network   numarticle_network      in_arti_network \n                   1                    0                    1 \n   numinarti_network         docu_network      numdocu_network \n                   0                    0                    0 \n       radio_network     numradio_network        course_anthro \n                   1                    0                    0 \n         high_anthro         colle_anthro          grad_anthro \n                   0                    0                    0 \n         book_anthro       numbook_anthro       article_anthro \n                   2                    0                    1 \n   numarticle_anthro       in_arti_anthro     numinarti_anthro \n                   0                    1                    0 \n         docu_anthro       numdocu_anthro         radio_anthro \n                   1                    0                    2 \n     numradio_anthro          needforclo1          needforclo2 \n                   0                    0                    0 \n         needforclo3          needforclo4          needforclo5 \n                   0                    0                    0 \n         needforclo6          needforclo7          needforclo8 \n                   0                    0                    0 \n         needforclo9         needforclo10         needforclo11 \n                   0                    0                    1 \n        needforclo12         needforclo13         needforclo14 \n                   0                    0                    0 \n        needforclo15         needforclo16         needforclo17 \n                   0                    0                    0 \n        needforclo18         needforclo19         needforclo20 \n                   0                    0                    0 \n        needforclo21         needforclo22         needforclo23 \n                   0                    0                    0 \n        needforclo24         needforclo25         needforclo26 \n                   0                    0                    0 \n        needforclo27         needforclo28         needforclo29 \n                   0                    0                    0 \n        needforclo30         needforclo31         needforclo32 \n                   0                    0                    0 \n        needforclo33         needforclo34         needforclo35 \n                   0                    0                    0 \n        needforclo36         needforclo37         needforclo38 \n                   0                    0                    0 \n        needforclo39         needforclo40         needforclo41 \n                   0                    0                    0 \n        needforclo42                  sex            education \n                   0                    0                    0 \n              income             religion             identity \n                   3                    0                    1 \n                 age       political_atti        english_level \n                   1                    0                    0 \n             ih_food            ih_sports            ih_school \n                   0                    0                    0 \n        ih_architect           ih_product             ih_langu \n                   0                    0                    0 \n          ih_network            ih_anthro           needforcog \n                   0                    0                    1 \n```\n:::\n\n```{.r .cell-code}\n# Expertise Ready Df ----\n\n# Create new data frame as analyzable \nexpertise6_new<-expertise6_new%>%\n  select(-stih_food,-r_ih_food,-stih_sports,-r_ih_sports,\n         -stih_school,-r_ih_school,-stih_architect,-r_ih_architect,\n         -stih_product,-r_ih_product,\n         -stih_langu,-r_ih_langu,-stih_network,-r_ih_network,\n         -stih_anthro,-r_ih_anthro,\n         -course_food,\n         -book_food,-article_food,\n         -course_sports,\n         -book_sports,-article_sports,\n         -course_school,\n         -book_school,-article_school,\n         -course_architect,\n         -book_architect,-article_architect,\n         -course_product,\n         -book_product,-article_product,\n         -course_langu,\n         -book_langu,-article_langu,\n         -course_network,\n         -book_network,-article_network,\n         -course_anthro,\n         -book_anthro,-article_anthro,\n        -needforclo1,-needforclo2,-needforclo3,-needforclo4,-needforclo5,\n        -needforclo6,-needforclo7,-needforclo8,-needforclo9,-needforclo10,\n        -needforclo11,-needforclo12,-needforclo13,-needforclo14,-needforclo15,\n        -needforclo16,-needforclo17,-needforclo18,-needforclo19,-needforclo20,\n        -needforclo21,-needforclo22,-needforclo23,-needforclo24,-needforclo25,\n        -needforclo26,- needforclo27,-needforclo28,-needforclo29,-needforclo30,\n        -needforclo31,-needforclo32,-needforclo33,-needforclo34,-needforclo35,\n        -needforclo36,-needforclo37,-needforclo38,-needforclo39,-needforclo40,\n        -needforclo41,-needforclo42)\n\n\n# change the data type of the variables to numeric\nexpertise6_new <- expertise6_new %>%\n  mutate_at(vars('know_food','know_sports','know_school','know_architect',\n                        'know_product','know_langu','know_network','know_anthro',\n                        'high_food', 'colle_food', 'grad_food',\n                        'numbook_food','numarticle_food',\n                        'numinarti_food', 'numdocu_food',\n                        'numradio_food',\n                        'high_sports', 'colle_sports', 'grad_sports',\n                        'numbook_sports','numarticle_sports',\n                        'numinarti_sports', 'numdocu_sports',\n                        'numradio_sports',\n                        'high_school', 'colle_school', 'grad_school',\n                        'numbook_school','numarticle_school',\n                        'numinarti_school','numdocu_school',\n                        'numradio_school',\n                        'high_architect', 'colle_architect','grad_architect',\n                        'numbook_architect',\n                        'numarticle_architect',\n                        'numinarti_architect', \n                        'numdocu_architect',\n                        'numradio_architect',\n                        'high_product', 'colle_product', 'grad_product',\n                        'numbook_product',\n                        'numarticle_product',\n                       'numinarti_product','numdocu_product',\n                        'numradio_product',\n                        'high_langu', 'colle_langu', 'grad_langu',\n                        'numbook_langu','numarticle_langu',\n                        'numinarti_langu', 'numdocu_langu',\n                        'numradio_langu',\n                        'high_network', 'colle_network', 'grad_network',\n                        'numbook_network','numarticle_network',\n                        'numinarti_network', 'numdocu_network',\n                        'numradio_network',\n                        'high_anthro', 'colle_anthro','grad_anthro',\n                        'numbook_anthro','numarticle_anthro',\n                        'numinarti_anthro', 'numdocu_anthro',\n                        'numradio_anthro'), as.numeric)\n```\n:::\n\n\n## Long format\n\nLong format of expertise dataset for factor analysis\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary('reshape2')\n\nexpertise6_factor <- melt(expertise6_new, id.vars = c(\"ID\",'duration',\"sex\" ,\"education\" ,\"income\",\"religion\",'identity','age','political_atti','english_level','needforcog'), \n                        measure.vars = c(\"ih_food\", \"ih_sports\",\"ih_school\",                                \"ih_architect\",\"ih_product\",\"ih_langu\",\"ih_network\",\"ih_anthro\",\n                       'know_food','know_sports','know_school','know_architect',\n                        'know_product','know_langu','know_network','know_anthro',\n                        'high_food', 'colle_food', 'grad_food',\n                        'numbook_food','numarticle_food',\n                        'numinarti_food', 'numdocu_food',\n                        'numradio_food',\n                        'high_sports', 'colle_sports', 'grad_sports',\n                        'numbook_sports','numarticle_sports',\n                        'numinarti_sports', 'numdocu_sports',\n                        'numradio_sports',\n                        'high_school', 'colle_school', 'grad_school',\n                        'numbook_school','numarticle_school',\n                        'numinarti_school','numdocu_school',\n                        'numradio_school',\n                        'high_architect', 'colle_architect','grad_architect',\n                        'numbook_architect',\n                        'numarticle_architect',\n                        'numinarti_architect', \n                        'numdocu_architect',\n                        'numradio_architect',\n                        'high_product', 'colle_product', 'grad_product',\n                        'numbook_product',\n                        'numarticle_product',\n                       'numinarti_product','numdocu_product',\n                        'numradio_product',\n                        'high_langu', 'colle_langu', 'grad_langu',\n                        'numbook_langu','numarticle_langu',\n                        'numinarti_langu', 'numdocu_langu',\n                        'numradio_langu',\n                        'high_network', 'colle_network', 'grad_network',\n                        'numbook_network','numarticle_network',\n                        'numinarti_network', 'numdocu_network',\n                        'numradio_network',\n                        'high_anthro', 'colle_anthro','grad_anthro',\n                        'numbook_anthro','numarticle_anthro',\n                        'numinarti_anthro', 'numdocu_anthro',\n                        'numradio_anthro'),\n                        sep = \"_\", variable.name = \"Category\", value.name = \"Score\")\n\n# Split the Category column into two columns based on the underscore separator\nexpertise6_factor <- expertise6_factor %>% separate(Category, into = c(\"Category\", \"Score_Type\"), sep = \"_\")\n\n## spread the data from long to wide format  ----\nexpertise6_fact <- expertise6_factor %>% spread(Category, Score)\n\n# change the score type to a factor\nexpertise6_fact$Score_Type<-as.factor(expertise6_fact$Score_Type)\n\n# convert the column ih to numeric\nexpertise6_fact$ih<-as.numeric(expertise6_fact$ih)\n```\n:::\n\n\n###Create another data frame to winsorize expertise variables before factor analysis\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexpertise6_wins_fact<-expertise6_fact\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}